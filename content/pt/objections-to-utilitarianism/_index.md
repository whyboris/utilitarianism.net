---
title: "Objections to Utilitarianism and Responses"
date: 2023-01-29
draft: false
menu: ["objections", "main"]
weight: 300
page: 0
description: "This chapter presents a toolkit of general strategies for responding to objections to utilitarianism, before introducing the most influential specific objections to the theory."
gradientTop: "#1F2A70"
gradientBottom: "#1F1E70"
---

> _"Bernard Williams... concluded a lengthy attack on utilitarianism by remarking: ‘The day cannot be too far off in which we hear no more of it.’ It is now more than forty years since Williams made that comment, but we continue to hear plenty about utilitarianism."_
>
> — Katarzyna de Lazari-Radek & [Peter Singer](/utilitarian-thinker/peter-singer)[^1]
{ .align-author-right }

{{< TOC >}}

Utilitarianism is a very controversial moral theory. Critics have raised many objections against it, and its defenders have responded with attempts to defuse them.

While our presentation focuses on utilitarianism, it's worth noting that many of the objections below could also be taken to challenge [other forms of consequentialism](/near-utilitarian-alternatives) (just as many of the [arguments for utilitarianism](/arguments-for-utilitarianism/) also apply to these related views). This chapter explores objections to utilitarianism and closely related views in contrast to non-consequentialist approaches to ethics.

## General Ways of Responding to Objections to Utilitarianism

Many objections rest on the idea that utilitarianism has counterintuitive implications. We can see these implications by considering concrete examples or _thought experiments_. For instance, in our article on the [rights objection](/objections-to-utilitarianism/rights), we consider the Transplant case:

> **Transplant:** Imagine a hypothetical scenario in which there are five patients, each of whom will soon die unless they receive an appropriate transplanted organ⁠—a heart, two kidneys, a liver, and lungs. A healthy patient, Chuck, comes into the hospital for a routine check-up and the doctor finds that Chuck is a perfect match as a donor for all five patients. Should the doctor kill Chuck and use his organs to save the five others?

At first glance, it seems that utilitarianism has to answer the question affirmatively. It's better that five people survive than that just one person does. But killing Chuck seems morally monstrous to many. This apparent implication of utilitarianism is taken as an argument against its being the correct moral theory.

Utilitarians can respond to such objections in four general ways. If we think of an objection or counterintuitive implication as akin to a shot fired at a theory, a defender of the theory might try to (i) dodge the bullet, (ii) disarm it or expose it as illusory, (iii) show that rivals are equally caught in the blast, or (iv) absorb the impact by "biting the bullet". To explain each strategy in turn:

To dodge the bullet, defenders of utilitarianism may seek to _accommodate the intuition_ underlying the objection by arguing that a sophisticated application of utilitarian principles avoids the counterintuitive implication. To more reliably promote good outcomes, sophisticated utilitarians recognize their cognitive limitations and [act in accordance with commonsense norms and heuristics](/utilitarianism-and-practical-ethics/#respecting-commonsense-moral-norms), other than in exceptional circumstances. If a critic merely claims that we should embrace or oppose certain norms _in practice_, utilitarians can often straightforwardly agree. (If the critic instead invokes outlandish hypotheticals, a different response may be needed.)

Second, to disarm or expose the threat as illusory (like the "shot" of a toy cap gun), one may instead attempt to _debunk the moral intuition_ invoked in a particular case. For example, one might try to show that the intuition resulted from an unreliable process.[^2] If a [debunking argument](/arguments-for-utilitarianism#evolutionary-debunking-arguments) succeeds, the targeted moral intuition should not be given much weight in our moral reasoning.

Third, to expand the blast radius, one might try to show that rival views—such as deontological or virtue ethical theories—_fare no better_ and have implications no less counterintuitive, in the relevant area, than those of utilitarianism. An objection can't give you overall reason to prefer a rival view if that rival view is equally undermined by careful consideration of the issue at hand.

Finally, one might simply _bite the bullet_ and accept a counterintuitive implication. To weaken the force of the blow, one might emphasize that the costs of accepting a counterintuitive implication may be outweighed by the force of [the arguments in favor of utilitarianism](/arguments-for-utilitarianism) and the [greater problems faced by other views (in other areas)](/arguments-for-utilitarianism/#the-poverty-of-the-alternatives). Our moral intuitions may pull us in multiple conflicting directions, making it impossible to find consistent and plausible principles without giving up on _some_ of our initial moral assumptions. We must carefully reflect upon which intuitions and theoretical commitments we regard as non-negotiable, and which we should be willing to compromise on in pursuit of “[reflective equilibrium](/arguments-for-utilitarianism#introduction-moral-methodology-amp-reflective-equilibrium)”, or the most plausible and coherent overall combination of moral verdicts and principles.

## The Utilitarian’s Toolkit

There are further ideas that utilitarians may appeal to in developing the above general strategies.

- _Keep hypotheticals at a distance_.[^2a] The distinction between utilitarianism’s [_criterion of rightness_ and its _recommended decision procedure_](/types-of-utilitarianism#multi-level-utilitarianism-versus-single-level-utilitarianism) is crucial to utilitarian attempts to _accommodate_ common intuitions. Given that utilitarianism is [fundamentally scalar](/types-of-utilitarianism/#reconstructing-rightness-maximizing-satisficing-and-scalar-utilitarianism), we needn't be committed to taking utilitarian verdicts as corresponding to the ordinary concept of "rightness". Common intuitions about “right” and “wrong” may be best understood as addressing the question of what norms we (as fallible agents) should endorse in practice, rather than what ideally ought to be done (by an omniscient being) in principle. If justified, this interpretive move can drastically reduce the apparent conflict between utilitarianism and commonsense moral intuitions.

- _Accommodate nearby intuitions_. More generally, utilitarians may seek to reduce their apparent conflict with commonsense by identifying _nearby_ intuitions that they _can_ accommodate. For example, if critics claim that a specific welfare-maximizing action is intuitively _wrong_, utilitarians may argue that our intuition here is better thought of tracking one of the following features:

  - that it would be good to _inculcate practical norms_ against actions of that type;
  - that a person willing to perform such an action would likely have _bad character_, and be likely to cause greater harms on other occasions;
  - that the action is _reckless_, or plausibly wrong _in expectation_, even if it happens to turn out (objectively) for the best.[^3]

- _Gobble up competing values_. Critics sometimes allege that utilitarians don’t value obviously good things like rights, freedom, virtue, equality, and the natural environment. But while these things may be obviously good, it's less obvious that they are all _non-instrumentally_ good. And utilitarians can certainly value them instrumentally. Moreover, utilitarians who accept an [objective list theory of well-being](/theories-of-well-being/#objective-list-theories) may even be able to give non-instrumental consideration to goods (like freedom and [beauty](/near-utilitarian-alternatives/#aesthetic-value)) that could plausibly be counted as welfare goods when part of a person’s life.

- _Stuff people into suitcases_. Rival moral theories may be undermined by appeal to the [veil of ignorance](/arguments-for-utilitarianism#the-veil-of-ignorance), and the related idea of _[ex ante Pareto](/arguments-for-utilitarianism/#ex-ante-pareto)_—or what it would be in _everyone’s_ best interests to agree to in advance (before learning about their particular position in life). Our intuitive reluctance to stick with the overall best policy can then start to seem [biased](/arguments-for-utilitarianism/#status-quo-bias). To make the point vivid, when faced with difficult trade-offs between conflicting interests, just imagine putting each affected person in a separate suitcase, and shuffling their positions.[^3a] All would then rationally endorse the utilitarian-recommended action. Resistance to utilitarian verdicts in suitcase-free scenarios thus looks like unjustified "special pleading" on behalf of those privileged by the status quo.

- _Look for neglected interests_. Putative counterexamples to utilitarianism ask us to _negatively judge_ an action that _does the most good_. Isn't that odd? It's worth considering what psychological mechanisms could explain such a judgment. Such cases commonly involve _unequal vividness_: we are implicitly led to focus our attention on a salient "victim", and pay much less attention to the greater harms to others that would result under the status quo.[^3b] Reflecting on this potential source of psychological distortion, and making a special effort to _attend equally_ to each individual in a scenario, may help to undermine the biasing effect. You may then find that you are less inclined to negatively judge the action that actually helps people the most.[^3c]

- _The Pluralist’s Dilemma_ (between extremism and arbitrariness). If you hold that there are non-utilitarian moral reasons (e.g. deontic constraints) that sometimes outweigh utilitarian reasons, this raises tricky questions about how the two kinds of reasons compare. If the non-utilitarian reason always trumps—no matter how great the cost to overall well-being—then this seems implausibly extreme. But the “moderate” pluralist alternative risks arbitrariness, due to lacking a clear account of where to draw the line, or precisely how much weight to give to non-utilitarian reasons relative to utilitarian ones.[^4]

- _Bang the drums of war_. We live in a _morally unusual world_. During high-stakes emergencies like fighting a just war, many activities that would otherwise seem [above and beyond the call of duty](/utilitarianism-and-practical-ethics/#demandingness), or even wrong, may instead be morally required—including risking your life, imposing burdens on your loved ones or leaving them for years, and killing enemy combatants. But in fact our “ordinary circumstances” involve horrific amounts of [preventable suffering](/acting-on-utilitarianism#opportunities-to-help-others), with stakes as high as any war. Utilitarian verdicts may thus be bolstered by noting that much sentient life is (metaphorically) under siege, and some moral heroism may accordingly be required to set things right.[^5]

- _Make winning distinctions_. [Different versions](/types-of-utilitarianism/) of utilitarianism may be more or less vulnerable to different objections. For example, a version of the view that combines [scalar](/types-of-utilitarianism/#reconstructing-rightness-maximizing-satisficing-and-scalar-utilitarianism), [expectational](/types-of-utilitarianism/#expectational-utilitarianism-versus-objective-utilitarianism), and [hybrid](/types-of-utilitarianism/#global-utilitarianism-and-hybrid-utilitarianism) elements may be better equipped to mitigate concerns about demandingness, cluelessness, and praiseworthy motivations. Objections to specifically [hedonistic](/theories-of-well-being/#hedonism) utilitarianism (such as the Experience Machine and Evil Pleasures objections) do not apply to utilitarians who accept a different [theory of well-being](/theories-of-well-being/).

Despite the silly labels, these are serious philosophical moves. We employ each, where appropriate, to respond to the specific objections listed below. (Students are encouraged, when reading an objection, to anticipate how to apply the utilitarian’s toolkit to address the objection at hand.)

## Specific Objections to Utilitarianism

In separate articles, we discuss the following critiques of utilitarianism:

{{< textbook-objections >}}

{{< next-page-objection hide-other="true" >}}

{{< how-to-cite >}}

{{< button >}}

## Resources and Further Reading

- Katarzyna de Lazari-Radek & Peter Singer (2017). _[Utilitarianism: A Very Short Introduction](https://global.oup.com/academic/product/utilitarianism-a-very-short-introduction-9780198728795)_. Oxford: Oxford University Press. Chapter 4: Objections.
- J. J. C. Smart & Bernard Williams (1973). _[Utilitarianism: For and Against](https://doi.org/10.1017/CBO9780511840852.001)_. Cambridge: Cambridge University Press.

[^1]: de Lazari-Radek, K. & Singer, P. (2017). _[Utilitarianism: A Very Short Introduction](https://global.oup.com/academic/product/utilitarianism-a-very-short-introduction-9780198728795)_. Oxford: Oxford University Press. Preface.
[^2]: For a discussion of evolutionary debunking arguments, see Hanson, R. (2002). [Why Health Is Not Special: Errors In Evolved Bioethics Intuitions](http://mason.gmu.edu/~rhanson/bioerr.pdf). _Social Philosophy & Policy_. 19(2): 153–79. See also the related discussion in Chapter 3: [Arguments for Utilitarianism](/arguments-for-utilitarianism#evolutionary-debunking-arguments).
[^2a]: Public health experts recommend maintaining social distance of 6 feet or more from silly hypothetical cases at all times, lest they [infect](/objections-to-utilitarianism/abusability/) your understanding of [what utilitarianism actually calls for in practice](/acting-on-utilitarianism/). If closer contact is required, protect yourself and others by first reading up on [the utilitarian case for respecting commonsense norms](/utilitarianism-and-practical-ethics/#respecting-commonsense-moral-norms), explained in Chapter 6.
[^3]: As further explained in our article on the [rights objection](/objections-to-utilitarianism/rights), standard “counterexamples” to utilitarianism invite us to imagine that a typically-disastrous class of action (such as killing an innocent person) just so happens, in this special case, to produce the best outcome. But the agent in the imagined case generally has no good basis for discounting the typical risk of disaster. So it would be unacceptably risky for them to perform the typically-disastrous act. We maximize expected value by avoiding such risks. For all practical purposes, utilitarianism recommends that we refrain from rights-violating behaviors. This constitutes a generalizable defense of utilitarianism against a wide range of alleged counterexamples.
[^3a]: Hare, C. (2016). [Should We Wish Well to All?](http://dx.doi.org/10.1215/00318108-3624764) _Philosophical Review_, 125(4): 451–472, pp. 454–455. See also the discussion in our Chapter 3: [Arguments for Utilitarianism](/arguments-for-utilitarianism/#ex-ante-pareto).
[^3b]: Sinhababu, N. (2013). [Unequal Vividness and Double Effect](https://philpapers.org/rec/SINUVA). _Utilitas_, 25 (3): 291-315. See also: Chappell, R.Y. & Yetter-Chappell, H. (2016). [Virtue and Salience](https://philpapers.org/rec/CHAVAS-3). _Australasian Journal of Philosophy_, 94 (3): 449-463.
[^3c]: At the very least, you should avoid the common mistake of thinking that utilitarian verdicts are unpopular "because contrary to most people's interests" (as is sometimes claimed in online debates). This mistake presumably stems from imagining oneself in the position of a possible "victim" of utilitarian sacrifice, where one is killed to save five, _without_ also imagining oneself in the position of any of the possible beneficiaries. You should realize that a policy of killing one to save five is _five times more likely to save your life_ than to end it. If the way you imagine the scenario doesn't reflect this fact, then you're imagining it wrong. Look for the neglected interests.
[^4]: By contrast, utilitarianism offers a clear and principled account of (e.g.) when constraints can reasonably be violated—namely, just when doing so would truly best serve overall well-being. Similarly for when it's worth damaging the natural environment, how to weigh small harms to many against grave harms to a few, and so on. That’s not to say that it will always be easy to _tell_ what utilitarianism recommends in real-life situations, since it can be difficult to predict future outcomes. But it's at least clear _in principle_ how different considerations weigh against each other, whereas other theories often do not offer even this much clarity. (Though utilitarians who accept an [objective list theory](/theories-of-well-being/#objective-list-theories) of well-being may face “pluralist’s dilemmas” of their own.)
[^5]: Of course, that’s not to suggest that the same particular actions are called for. Adopting a "war-like" stance outside of war might be expected to prove counterproductive. The point is just that the stakes are high enough that we shouldn’t necessarily expect truly moral advice, in our circumstances, to be _comfortable_.
