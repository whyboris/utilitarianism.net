---
title: "A Objeção da Total Desinformação"
slug: "total-desinformacao"
authors: "Chappell, R.Y."
date: 2023-03-08
type: "page"
draft: false
menu: ["objections"]
weight: 208
page: 8
description: "O utilitarismo é comprometido por nossa incapacidade de prever as consequências das nossas ações no longo prazo? Este artigo investiga se os utilitaristas ainda podem ser guiados pelo valor esperado de médio prazo quando ele for pequeno em comparação com o valor ou o desvalor potencial das consequências desconhecidas no longo prazo."
gradientTop: "#260380"
gradientBottom: "#6F4BC9"
---

{{< TOC >}}

O utilitarismo nos direciona a promover o bem-estar geral, mas não podemos ter certeza sobre como fazer isso. Pior ainda, há fortes razões para pensarmos que estamos completamente _desinformados_ sobre as consequências das nossas ações no longo prazo, incluindo sobre se elas serão positivas ou negativas no geral. Isso torna o utilitarismo impraticável? É uma razão para pensarmos que o utilitarismo é _falso_?

## A Objeção Epistêmica ao Consequencialismo

_[Consequentialism and Cluelessness](https://doi.org/10.1111/j.1088-4963.2000.00342.x)_ [Consequencialismo e Total Desinformação] de James Lenman apresenta uma influente _objeção epistêmica_ contra  o [consequencialismo](https://www.utilitarismo.net/types-of-utilitarianism#consequentialism) (e assim, por conseguinte, contra o utilitarismo). Podemos reconstruir o argumento aproximadamente da seguinte forma:

> P1. Não fazemos ideia de quais serão os efeitos de qualquer uma de nossas ações no longo prazo.
>
> P2. Mas os efeitos no longo prazo determinam o que devemos fazer, segundo o consequencialismo. Logo, se o consequencialismo é verdade, não fazemos ideia do que realmente devemos fazer — nossas razões para agir[^1] se encontram além do nosso alcance epistêmico.
>
> P3. Mas uma teoria ética adequada deve orientar a ação — não pode postular razões além do nosso alcance epistêmico.
>
> Portanto,
>
> C. O consequencialismo não é uma teoria ética adequada.

Examinemos cada um das três premissas por sua vez.

### Premissa 1: Total Desinformação sobre o Longo Prazo

Imagine um médico salvando a vida de uma mulher grávida muitos séculos atrás.[^2] Isso parece um ato claramente bom. Infelizmente, acontece que a mulher era uma ancestral de Hitler. Logo, o ato aparentemente bom acabou tendo consequências efetivamente desastrosas no geral.

Esse exemplo ilustra como poderíamos não captar os efeitos das nossas ações no longo prazo. Mas a ideia se generaliza até para ações menos dramáticas, já que pequenas mudanças podem se propagar de modos imprevisíveis no futuro. Por exemplo, as nossas escolhas sobre dirigirmos ou não num dado dia irá "promover ou delongar as jornadas de incontáveis outros indivíduos, pelo menos em termos de alguns poucos segundos",[^3] e eles, por sua vez, irão afetar ligeiramente outros indivíduos. A cadeia causal acabará (mesmo que ligeiramente) afetando o momento em que um casal conceberá uma criança. Irá fertilizar o óvulo um esperma diferente daquele que o fertilizaria numa situação alternativa, levando ao nascimento de uma criança inteiramente diferente. Essa pessoa diferente irá fazer escolhas de vida diferentes, impactando o momento de concepção de outros casais e a identidade das crianças que eles produzirão, formando rapidamente um futuro cada vez mais diferente. Como resultado, devemos esperar que nossas ações cotidianas tenham consequências momentosas — porém imprevisíveis — no longo prazo. Alguns desses efeitos certamente serão muito ruins e outros, muito bons. (Podemos fazer alguns ditadores genocidas virem à existência, e impedir que outros venham à existência, em mil anos.) E não fazemos ideia de como uma coisa irá compensar a outra.

As consequências do longo prazo dominam as do curto prazo em termos de valor total. E porque geralmente não podemos prever as consequências das nossas ações no longo prazo, decorre que geralmente não podemos prever as consequências das nossas ações _no geral_.

Mas pode haver algumas exceções. Os proponentes do [longtermismo](https://www.utilitarismo.net/utilitarianism-and-practical-ethics#longtermism) creem que algumas ações — como [reduzir riscos existenciais](https://www.utilitarismo.net/acting-on-utilitarianism#existential-risk-reduction) — têm um valor esperado robustamente positivo no longo prazo. Logo, no mínimo, a subconclusão (premissa 2) precisa ser enfraquecida, transformando-se na afirmação de que não fazemos ideia do que fazer _além de trabalharmos na redução de riscos existenciais_. Mas até essa afirmação enfraquecida continuaria a ser surpreendente: certamente parece que _também_ temos uma boa razão para salvarmos vidas no aqui e agora. A próxima seção avalia se isso é verdade.

### Premissa 2: Total Desinformação e Valor Esperado

A resposta natural a preocupações sobre total desinformação é irmos em direção ao [consequencialismo expectacional](https://www.utilitarismo.net/types-of-utilitarianism#expectational-utilitarianism-versus-objective-utilitarianism): promover o valor _esperado_ em vez do valor _efetivo_. Além disso, enquanto [teoria multinível](https://www.utilitarismo.net/types-of-utilitarianism#multi-level-utilitarianism-versus-single-level-utilitarianism), o utilitarismo aceita que possamos promover o valor esperado melhor ao [dependermos de heurísticas do que ao fazermos cálculos explícitos](https://www.utilitarismo.net/utilitarianism-and-practical-ethics/#respecting-commonsense-moral-norms) sobre as probabilidades de literalmente todo resultado possível. Logo, se salvarmos vidas no médio prazo geralmente tem valor esperado positivo, isso bastaria para derrotarmos a objeção da total desinformação.

Lenman distingue as consequências "visíveis" (epistemicamente acessíveis) de uma ação das "invisíveis" (inteiramente inconhecíveis).[^4] Fazendo-se uso dessa distinção, surge logo um argumento de que salvar vidas tem valor esperado positivo. Afinal, se não fazemos ideia de quais serão as consequências de uma ação no longo prazo, essas considerações "invisíveis" são (dadas as nossas evidências) simplesmente _silenciosas_ — ou seja, não falam nem a favor, nem contra nenhuma opção particular. Logo, as razões visíveis triunfam, sem oposição. Por exemplo, salvar a vida de uma criança tem um valor esperado de "+1 vida salva", o que não muda quando se salienta a nossa ignorância sobre o longo prazo.

Lenman não se impressiona com essa resposta,[^5] mas as razões que ele oferece são altamente contestáveis. Aqui focaremos em suas duas objeções principais.[^6]

Primeiro, ele sugere que os consequencialistas expectacionais devem depender de princípios probabilísticos de indiferença controversos (a ideia de que, por padrão, devemos presumir que toda possibilidade é igualmente provável).

Em resposta, Hilary Greaves argumenta que alguns princípios restritos de indiferença parecem claramente justificados em casos simples de total desinformação, sejam quais forem os problemas que se possam aplicar a tal princípio que seja totalmente geral.[^7] Afinal, pareceria inteiramente injustificado termos expectativas assimétricas (em vez de uma do tipo 50/50) sobre se salvar a vida de uma pessoa qualquer agora tem mais probabilidade de aleatoriamente causar ou prevenir a ocorrência de genocídios milênios no futuro. Logo, podemos razoavelmente ignorar tais fatores causais aleatórios.

No entanto, como a própria Greaves observa, isso deixa em aberto casos de "total desinformação complexa", que envolvem razões para pensarmos que uma opção é _sistematicamente melhor_ que outra para o futuro no longo prazo, outras razões para julgarmos o _contrário_ e não está claro como pesar as razões conflitantes em comparação umas com as outras.[^8] Por exemplo, se evitar mortes de crianças da malária tende a resultar numa população global duradouramente maior, há algumas razões para julgar isso positivamente e outras razões para julgar isso negativamente no geral (devido à "superpopulação"[^9]). Se estamos confiantes sobre um efeito sistemático, mas não temos certeza da sua direção, é menos óbvio que possamos razoavelmente ignorá-lo. No mínimo, não parece que o princípio da indiferença se aplica adequadamente aqui: não parece justificado presumir que uma população maior seja igualmente propensa a ser boa ou ruim.

Mas os consequencialistas podem, não obstante isso, repetir o argumento anterior de que razões "invisíveis" (inconhecíveis) não podem guiar nossas ações, de modo que as únicas razões restantes são as "visíveis" (conhecíveis), que se pronunciam a favor de salvar vidas e outros atos aparentemente bons até que se prove o contrário. Essa resposta não depende de nenhum princípio de indiferença. Em vez disso, enfatiza que se encontra sobre o cético o ônus de mostrar _como_ devemos revisar nossos juízos iniciais de que salvar a vida de uma criança tem um valor esperado de "+1 vida salva". Muito mal parece melhor jogarmos a toalha em desespero diante da total desinformação complexa. Logo, até que nos apresentem uma melhor alternativa, parece mais razoável seguirmos com nossos juízos iniciais.[^10]

Segundo, Lenman presume que, dada a simples imensidão daquilo de "invisível" que está em jogo no longo prazo, a razão "visível" para os consequencialistas salvarem uma vida deve ser extremamente fraca — meramente "uma gota no oceano".[^11] Mas isso é um equívoco. Em termos absolutos, salvar uma vida é incrivelmente importante. A presença de coisas em jogo _ainda maiores_ não modifica o peso absoluto dessa razão.

Você poderia presumir que, se o consequencialismo fosse verdade, a força de uma razão deveria ser proporcional à probabilidade de a ação maximizar o valor no geral. Com essa pressuposição, visto que é infimamente improvável que o valor de uma vida faça a balança pender para um lado ao compararmos o valor de longo prazo de cada opção, salvar uma vida deve ser uma razão "extremamente fraca" para selecionarmos uma opção em vez de outra. Mas a pressuposição inicial é falsa. A força de uma razão consequencialista é dada pelo seu valor (esperado) associado em termos absolutos: o que importa é o tamanho da gota, não o tamanho do oceano.

### Por que o Valor Esperado Importa

Objeções específicas à parte, a preocupação mais ampla de Lenman é que não está claro _por que_ os consequencialistas deveriam preferir prospectos com maior valor esperado, se estamos totalmente desinformados sobre as efetivas consequências.[^12]

Essa é uma questão sutil. O propósito de sermos guiados pelo valor esperado _não_ é aumentarmos a nossa probabilidade de fazer a coisa objetivamente correta, visto que alguns prospectos arriscados com pouca probabilidade de resultar bem, no entanto, podem valer o risco.[^13] _Grosso modo_, é uma maneira de _promover o valor da melhor forma que podemos_ dada a informação disponível para nós (conciliando o que está em jogo com as probabilidades).[^14] Afinal, se houvesse uma alternativa melhor que pudéssemos identificar, seguir a _ela_ então maximizaria o valor esperado. Logo, se a crítica de Lenman fosse precisa, implicaria não que não há motivação para maximizarmos o valor esperado, mas antes que (ao contrário das aparências) salvar uma vida carece de valor esperado, no fim das contas.

Se, em vez disso, nos fazem a pergunta "Por que pensar que salvar uma vida tem valor esperado positivo?", podemos simplesmente responder "Por que não? É visivelmente positivo; dificilmente se pode demonstrar que considerações invisíveis contam contra!"

Admita-se que a total desinformação diante de uma imensidão de coisas invisíveis em jogo no longo prazo pode induzir angústia. Deve nos fazer desejar intensamente mais informação e nos motivar a buscar investigações longotermistas sempre que possível. Mas se nenhuma tal investigação se provar viável, não devemos confundir esse sentimento residual de angústia com uma razão para duvidarmos que podemos ainda ser guiados racionalmente pelas considerações em escala menor que de fato enxergamos. Para que estas razões sejam comprometidas, não basta que o cético acene para o profundo desconhecido. Desconhecidos, em si mesmos, não são epistemicamente comprometedores (algo que devora avidamente tudo o mais que seja conhecido). Para comprometermos um veredicto de valor esperado, precisamos mostrar que algum veredicto alternativo é epistemicamente superior. Proponentes da objeção epistêmica, como os céticos radicais em muitos outros contextos filosóficos, não fizeram isso.[^15]

### Premissa 3: A Possibilidade de Total Desinformação Moral

A premissa final do argumento epistêmico afirma que _uma teoria ética adequada deve guiar a ação_: não pode postular razões morais além do nosso alcance epistêmico. Mas por que pensar isso? Podemos certamente _ter a esperança_ de uma orientação à ação, mas se o mundo não coopera — se somos privados de acesso aos fatos moralmente relevantes —, parece então mais apropriado culpar o mundo, não uma teoria moral que (com razão) reconhece que eventos imprevisíveis ainda importam.

O utilitarismo enquanto teoria moral pode ser entendido como algo que combina (i) o [bem-estarismo imparcial agregativo](https://www.utilitarismo.net/types-of-utilitarianism#the-definition-of-utilitarianism) enquanto explicação das metas morais corretas (isto é, o que importa, ou com o que devemos nos importar) com (ii) o princípio teleológico de que as nossas razões para agir são dadas pela aplicação da _racionalidade instrumental_ às _metas morais corretas_. Isso quer dizer que uma ação equivocada deve ter origem ou em metas morais equivocadas, ou na busca de metas morais de um modo ineficaz.

Uma objeção genuinamente ameaçadora ao utilitarismo deve então comprometer uma dessas duas subafirmações. O mais comum é os críticos desafiarem a explicação utilitarista sobre o que importa, por exemplo ao sugerirem que devemos também dar importância de modo independente a [direitos](https://www.utilitarismo.net/objections-to-utilitarianism/rights), à [igualdade](https://www.utilitarismo.net/objections-to-utilitarianism/equality) ou aos [nossos mais próximos e mais queridos](https://www.utilitarismo.net/objections-to-utilitarianism/special-obligations). Mas a objeção da total desinformação não nos dá razão alguma para duvidarmos de que [pessoas futuras importam genuinamente](https://www.utilitarismo.net/utilitarianism-and-practical-ethics#longtermism), e assim que agentes morais devem se importar com o bem-estar de pessoas futuras.[^16] Talvez seja simplesmente um fato lamentável do mundo que nós verdadeiramente não saibamos como alcançar as nossas metas morais.

Por exemplo, suponha que você tenha de puxar uma alavanca mágica ou para a esquerda, ou para a direita, e lhe digam apenas que o destino do mundo depende da posição resultante da alavanca. Você não tem modo algum de saber qual opção salvará o mundo. Mas seria estranho concluir a partir disso que o destino do mundo não importa, moralmente falando. Pareceria mais razoável concluir que você está numa situação complicada, e (na ausência de mais evidências sobre qual opção é mais dada a salvar o mundo) a moralidade não pode lhe oferecer nenhuma orientação útil nessas circunstâncias particulares.

Logo, a premissa 3 parece equivocada.[^17] É sempre possível que agentes possam ser incapazes de saber como alcançar suas metas morais. Em tais casos, a teoria moral verdadeira pode não guiar a ação, mas isso não compromete a sua verdade. Não há nenhuma razão fundamentada em princípios para preferirmos uma teoria alternativa que ofereça “orientação” extra sem efetivamente nos ajudar a alcançar as metas morais corretas.

Todas as teorias plausíveis devem concordar que as consequências gerais estão _entre_ as considerações que importam (ainda que elas venham a divergir do consequencialismo ao afirmarem que outros fatores importam além disso). Os deontologistas moderados, por exemplo, postulam restrições deônticas extras, mas permitem que elas possam ser anuladas quando há o bastante em jogo. Isso sugere que todos os teóricos morais, não só os consequencialistas, devem lidar com a objeção da total desinformação. Esses teóricos podem replicar similarmente que a total desinformação é (no máximo) uma dificuldade prática e não uma objeção à _verdade_ de uma teoria moral.[^18]

## Conclusão

Há razão para duvidarmos se preocupações sobre total desinformação realmente apresentam uma _objeção_ ao utilitarismo em absoluto. Talvez a total desinformação só seja uma implicação lamentável das circunstâncias em que nos encontramos. No entanto, considerações de valor esperado, mediadas por heurísticas plausíveis, podem continuar a nos orientar. Poderíamos razoavelmente tomar o valor esperado no médio prazo pelas suas aparências, ainda que não façamos ideia das consequências dos atos em questão no longo prazo. Além disso, ainda que a total desinformação no longo prazo domine o valor esperado no médio prazo, pode ainda haver algumas opções — como o trabalho para reduzirmos riscos existenciais — que tenham um valor esperado apreciavelmente positivo no longo prazo. Logo, o utilitarismo não precisa nos deixar inteiramente desinformados sobre [como agir](https://www.utilitarismo.net/acting-on-utilitarianism), no fim das contas.

{{< next-page-objection >}}

{{< how-to-cite >}}

{{< button >}}

### Recursos e Leituras Adicionais

- Joanna Burch-Brown (2014). [Clues for Consequentialists](https://doi.org/10.1017/S0953820813000289). _Utilitas_, 26(1): 105–119.
- Hilary Greaves (2016). [Cluelessness](https://doi.org/10.1093/arisoc/aow018). _Proceedings of the Aristotelian Society_, 116(3): 311–339.
- James Lenman (2000). [Consequentialism and Cluelessness](https://doi.org/10.1111/j.1088-4963.2000.00342.x). _Philosophy and Public Affairs_, 29(4): 342–370.
- Andreas Mogensen (2021). [Maximal Cluelessness](https://doi.org/10.1093/pq/pqaa021). _The Philosophical Quarterly_, 71: 141–162.
- Andreas Mogensen & William MacAskill (2021). [The Paralysis Argument](http://hdl.handle.net/2027/spo.3521354.0021.015). _Philosophers' Imprint_ 21 (15): 1–17.
- David Thorstad, and Andreas Mogensen (2020). [Heuristics for clueless agents: how to get away with ignoring what matters most in ordinary decision-making](https://globalprioritiesinstitute.org/david-thorstad-and-andreas-mogensen-heuristics-for-clueless-agents-how-to-get-away-with-ignoring-what-matters-most-in-ordinary-decision-making/). _GPI Working Paper_ 2-2020.

[^1]:
     Isto é, as considerações que contam a favor de agirmos de uma maneira em vez de outra.

[^2]:
     Adaptado de James Lenman (2000) [Consequentialism and Cluelessness](https://doi.org/10.1111/j.1088-4963.2000.00342.x). _Philosophy and Public Affairs_, 29(4): 342–370, p. 344.

[^3]:
     Hilary Greaves (2016). [Cluelessness](https://doi.org/10.1093/arisoc/aow018). _Proceedings of the Aristotelian Society_, 116(3): 311–339, p. 314.

[^4]:
     Lenman (2000), p. 363.

[^5]:
     Veja Lenman (2000), pp. 353–359.

[^6]:
     Ele oferece quatro objeções ao todo. A quarta pressupõe a segunda, e assim é abordada pela nossa resposta a ela. A terceira questiona que precisamos distinguir entre duas razões diferentes para julgar que um ato carece de valor esperado: (i) poderíamos _saber_ que ele não faz diferença alguma ou (ii) poderíamos estar _totalmente desinformados_ sobre se ele é incrivelmente bom ou incrivelmente ruim. Dado que esses dois estados epistêmicos são tão diferentes, Lenman raciocina, não faz sentido tratá-los da mesma forma.

     É verdade que há uma diferença considerável, mas é um erro presumir que algo de moralmente significativo deva mudar o modo como avaliamos _atos_, quando frequentemente _atitudes_ são mais adequadas para refletir tal significância. Devemos sentir imensamente mais angústia e ambivalência — e desejar intensamente que mais informação esteja disponível — num caso de "total incerteza" com muito em jogo do que num caso com "zero conhecido". Isso parece suficiente para capturar a diferença.

[^7]:
     Greaves (2016), section IV.

[^8]:
     Greaves (2016), section V. Veja também Andreas Mogensen (2020). [Maximal Cluelessness](https://doi.org/10.1093/pq/pqaa021). _The Philosophical Quarterly_, 71: 141–162.

[^9]:
     Para uma exploração sobre se o mundo está superpovoado ou subpovoado, veja Ord, T. (2014). [Overpopulation or Underpopulation?](http://amirrorclear.net/files/overpopulation-or-underpopulation.pdf), em Ian Goldin (ed.), _[Is the World Full?](https://doi.org/10.1093/acprof:oso/9780199677771.001.0001)_. Oxford: Oxford University Press.

[^10]:
     Para uma defesa relacionada da "racionalidade processual" de dependermos de heurísticas diante da total desinformação, veja David Thorstad, and Andreas Mogensen (2020), [Heuristics for clueless agents: how to get away with ignoring what matters most in ordinary decision-making](https://globalprioritiesinstitute.org/david-thorstad-and-andreas-mogensen-heuristics-for-clueless-agents-how-to-get-away-with-ignoring-what-matters-most-in-ordinary-decision-making/). _GPI Working Paper 2, 2020_.

     Se vale a pena avaliarmos preocupações de superpopulação mais a fundo dependerá de fatores como: (i) quantos recursos estão em jogo — mais investigações plausivelmente se justificam para um financiador direcionando bilhões de dólares do que para um indivíduo doando algumas centenas de dólares —; e (ii) quão tratável parece a incerteza, ou qual é o valor de informação esperado de investigamos mais. Para um pequeno doador com pouca chance de resolver rapidamente a sua incerteza com frequência o mais razoável será ignorar inteiramente a total desinformação complexa.

[^11]:
     Lenman (2000), p. 356.

[^12]:
     Lenman (2000), p. 360.

[^13]:
     Por exemplo, uma chance de 10% de salvar um milhão de vidas é melhor em expectativa do que salvar uma vida com certeza, ainda que esta última opção tenha 90% de chance de gerar um resultado melhor. As grandezas e probabilidades exatas importam, não só seja lá o que "mais provavelmente" será (ainda que ligeiramente) melhor.

[^14]:
     Uma importante característica da maximização do valor esperado é que não podemos esperar nenhuma alternativa subjetivamente identificável para fazermos melhor no limite (isto é, imaginando casos como decisões que são repetidas um número suficiente de vezes, perpassando diferentes mundos possíveis se for necessário).

[^15]:
     Uma proposta interessante é que devemos antes ter _crenças imprecisas_ cobrindo uma ampla gama de pontos de crenças aparentemente razoáveis. Uma preocupação com tais propostas é que elas podem acabar implicando que temos tanta razão para apoiar a _Fundação Para A Malária_ quanto a _Fundação Contra A Malária_, o que pode comprometer a aparente razoabilidade das pressuposições iniciais. Cf. Andreas Mogensen (2021) [Maximal Cluelessness](https://doi.org/10.1093/pq/pqaa021).

[^16]:
     É de impressionar que até Lenman (2000), p. 364, aceite que "consequências invisíveis de ações muito plausivelmente importam também", mas acrescente que "não há nenhuma razão clara para supormos que essa importância seja uma questão de significância moral mais do que as consequências, visíveis ou não, de terremotos ou impactos de meteoros (embora elas possam certamente importar enormemente) precisam ser questões de preocupação, particularmente, moral. Nada há de particularmente implausível aqui. Quer simplesmente dizer, por exemplo, que os crimes de Hitler, embora tenham sido algo terrível, não são algo que possamos judiciosamente mencionar em discussões sobre os defeitos e excelências morais de [alguém que salvou a vida de ancestral distante de Hitler]."

     Esse é um estranho uso de "significância moral". Agentes morais claramente devem se importar com terremotos, impactos de meteoros e ditadores genocidas futuros. (No mínimo, devemos preferir que haja menos de tais coisas, como parte da nossa preocupação beneficente pelos outros em geral). Um agente que fosse verdadeiramente _indiferente_ a essas coisas não seria um agente virtuoso: a sua indiferença revela uma fria desconsideração às pessoas futuras. Logo, poderia constituir um "defeito moral" não se importar com tais eventos nocivos.

     Por outro lado, se Lenman realmente só quer dizer que _quais consequências imprevisíveis efetivamente ocorrerão_ não deveria afetar a nossa avaliação dos "defeitos e excelências morais" de alguém, isso então parece um truísmo que de modo algum ameaça o consequencialismo. É uma ideia familiar que muitas formas de avaliação de agente (p. ex., racionalidade, virtude, etc.) são "internistas": sobrevêm às propriedades intrínsecas do agente, e não ao que ocorre no mundo exterior, além do seu controle. Os [utilitaristas híbridos](https://www.utilitarismo.net/types-of-utilitarianism#global-utilitarianism-versus-hybrid-utilitarianism) combinam confortavelmente tal internismo quanto às avaliações de agente com uma explicação utilitarista das nossas razões para agir.

[^17]:
     A não ser que seja interpretado de tal forma a não demandar mais orientação onde nenhuma for possível. Embora certamente esteja tudo bem termos razões relativas a fatos que ultrapassam o nosso alcance epistêmico, uma versão mais convincente da premissa poderia simplesmente afirmar que razões fundamentadas em evidências devem estar dentro do nosso alcance epistêmico. Mas daí ela arrisca desabar numa mera tautologia: por definição, as "razões relativas a evidências" postuladas por qualquer teoria — incluindo o consequencialismo — estarão epistemicamente acessíveis (presumindo que "evidências" e "acesso epistêmico" se acompanhem). A questão antes se torna quais razões relativas a evidências (se houver) a teoria implica que temos.

[^18]:
     Embora haja alguma razão para pensarmos que as dificuldades práticas possam ser ainda piores para os não consequencialistas. Veja Andreas Mogensen & William MacAskill (2021). [The Paralysis Argument](http://hdl.handle.net/2027/spo.3521354.0021.015). Philosophers’ Imprint 21 (15): 1–17.
