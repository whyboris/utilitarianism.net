---
title: "Argumente für Utilitarismus"
slug: "argumente-fur-utilitarismus"
date: 2023-01-29
draft: false
menu: "main"
weight: 103
description: "In diesem Kapitel wird das reflexive Gleichgewicht als moralische Methodik erläutert. Es werden mehrere Argumente für den Utilitarismus gegenüber nicht-konsequentialistischen Ansätzen in der Ethik angeführt."
gradientTop: "#012147"
gradientBottom: "#084BC7"
---

{{< TOC >}}

## Einführung: Moralische Methodologie und reflexives Gleichgewicht

Man kann eine Moraltheorie nicht _beweisen_. Welches Argument man auch vorbringt, es ist immer möglich, dass andere die Prämissen des Arguments ablehnen — wenn sie bereit sind, die Implikationen dieser Ablehnung zu akzeptieren. Verschiedene Theorien bieten unterschiedliche Vorteile. In diesem Kapitel werden einige der wichtigsten Überlegungen dargelegt, die plausiblerweise für den Utilitarismus sprechen. Eine vollständige Betrachtung muss auch die Nachteile des Utilitarismus (oder die Vorteile seiner Konkurrenten) berücksichtigen, welche im Kapitel [Einwände gegen den Utilitarismus](/einwande) behandelt werden. Erst dann lässt sich ein Gesamturteil darüber fällen, welche Moraltheorie insgesamt am besten oder am plausibelsten erscheint.

Zu diesem Zweck wenden Moralphilosophen in der Regel die Methodik des _reflexiven Gleichgewichts_ an. Dabei werden zwei Arten von Evidenz in Bezug auf Moraltheorien abgewogen:

1. Intuitionen zu bestimmten Fällen (Gedankenexperimente).
2. allgemeine theoretische Überlegungen, einschließlich der Plausibilität der _Prinzipien_ der Theorie oder systematischer Behauptungen darüber, was wichtig ist.

Allgemeine Prinzipien können durch vermeintliche _Gegenbeispiele_ in Frage gestellt werden oder durch Fälle, in denen sie ein intuitiv falsches Urteil abgeben. Als Reaktion auf solche vermeintlichen Gegenbeispiele müssen wir die Stärke der fallbasierten Intuition gegen die inhärente Plausibilität des in Frage gestellten Prinzips abwägen. Dies könnte _entweder_ dazu führen, das Prinzip zu revidieren, um den Intuitionen zu den entsprechenden Fällen Rechnung zu tragen, _oder_ es lässt einen sein Urteil über die spezifischen Fälle überdenken, wenn man das allgemeine Prinzip als besser gestützt ansieht (insbesondere wenn man in der Lage ist, die gegnerische Intuition als auf einem impliziten Fehler oder einer Verwirrung beruhend „wegzuerklären“).

Wie wir sehen werden, stützen sich die Argumente für den Utilitarismus überwiegend auf allgemeine theoretische Überlegungen. [Einwände gegen Utilitarismus](/einwande) können in jeder Form erfolgen, aber viele der drängendsten Einwände beziehen sich auf Gedankenexperimente, bei denen utilitaristische Urteile kontraintuitiv scheinen.

Es gibt keine neutrale, nicht zirkuläre Antwort auf die Frage, wie man solche Konflikte lösen sollte.[^1] Diese Konflikte erfordern Urteilsvermögen; verschiedene Menschen können je nach ihrem philosophischen Temperament auf unterschiedliche Weise reagieren. Generell gilt, dass sich Menschen, die _systematisches Theoretisieren_ bevorzugen, eher zum Utilitarismus ([und verwandten Ansichten](/utilitarismus-nahe-alternativen)) hingezogen fühlen, während Menschen, die sich an die Intuition des gesunden Menschenverstandes halten, weniger von den theoretischen Vorzügen des Utilitarismus beeindruckt sind. Die Betrachtung der nachstehenden Argumente kann daher nicht nur den Utilitarismus beleuchten; sie kann auch helfen, das eigene philosophische Temperament zu erkennen!

Obwohl wir uns in unserer Darstellung auf den Utilitarismus konzentrieren, ist es erwähnenswert, dass viele der nachstehenden Argumente auch zur Unterstützung [anderer Formen des welfaristischen Konsequentialismus](/utilitarismus-nahe-alternativen) herangezogen werden könnten (ebenso wie viele der [Einwände gegen Utilitarismus](/einwande) auch für diese verwandten Ansichten gelten). In diesem Kapitel werden Argumente für Utilitarismus und eng verwandte Ansichten gegenüber nicht-konsequentialistischen Ansätzen in der Ethik untersucht.

## Argumente für Utilitarismus

### Was grundsätzlich wichtig ist

Moraltheorien dienen dazu, festzustellen, _was grundsätzlich wichtig ist_. Utilitarismus bietet eine besonders überzeugende Antwort auf diese Frage.

Fast jeder würde der utilitaristischen Ansicht, dass Leiden schlecht und [Wohlergehen](/theorien-uber-wohlergehen) gut ist, zustimmen. Was könnte offensichtlicher sein? Wenn irgendetwas moralisch von Bedeutung ist, zählt menschliches Wohlergehen sicherlich dazu. Da es zudem [willkürlich](https://utilitarianism.net/guest-essays/utilitarianism-and-nonhuman-animals/) wäre, moralische Rücksichtnahme auf unsere eigene Spezies zu beschränken, sollten wir stattdessen zu dem Schluss kommen, dass Wohlergehen im Allgemeinen das ist, was zählt. Das heißt, wir sollten wollen, dass es empfindungsfähigen Lebewesen so gut wie möglich geht (ob das nun auf die Maximierung von [Freude](https://utilitarianism.net/theories-of-wellbeing#hedonism), auf [Wunscherfüllung](https://utilitarianism.net/theories-of-wellbeing#desire-theories) oder auf andere [Komponenten von Wohlergehen](https://utilitarianism.net/theories-of-wellbeing#objective-list-theories) hinausläuft).

Könnte etwas anderes wichtig_er_ sein? Ein solcher Vorschlag kann rätselhaft erscheinen. Man bedenke: Es ist (normalerweise) falsch zu stehlen.[^2] Diese Aussage ist plausibel, weil Stehlen tendenziell _schädlich_ ist und das Wohlergehen von Personen mindert.[^3] Im Gegensatz dazu sind die meisten Menschen offen für eine umverteilende Besteuerung, wenn diese es Regierungen ermöglicht, Leistungen zu erbringen, die das Gesamtwohl in einer Gesellschaft zuverlässig steigern. Es ist also nicht so, dass der Einzelne ein natürliches Recht darauf hat, dass man ihm nicht in die Quere kommt, egal was passiert. Bei der Beurteilung institutioneller Regelungen (wie zum Beispiel des Eigentums- und Steuerrechts) erkennen wir an, dass es darauf ankommt, Regelungen zu finden, die tendenziell zu _insgesamt guten Ergebnissen_ führen, und dass der wichtigste Faktor, der ein Ergebnis zu einem _guten_ Ergebnis macht, darin besteht, dass er _Wohlergehen fördert_.[^4]

Eine solche Argumentation könnte es rechtfertigen, Utilitarismus als Standardausgangspunkt für das Theoretisieren über Moral zu behandeln.[^5] Wenn jemand behaupten will, dass es noch andere moralische Erwägungen gibt, die Vorrang vor dem _Gesamtwohl_ haben (und damit die Bedeutung der Rettung von Leben, der Verringerung von Leiden und der Förderung von Wohlergehen übertrumpfen), steht sie vor der Herausforderung, zu erklären, _wie_ das möglich sein könnte. Viele gängige moralische Regeln (wie die, die Diebstahl, Lügen oder das Brechen von Versprechen verbieten) haben zwar keinen explizit utilitaristischen Inhalt, aber dennoch eine klare utilitaristische Begründung. Würden sie im Allgemeinen kein Wohlergehen fördern — sondern Menschen aktiv schaden — gäbe  es keinen erkennbaren Grund mehr, dass Menschen sie trotzdem befolgen. Die Befolgung und Durchsetzung _schädlicher_ moralischer Regeln (wie zum Beispiel das Verbot gleichgeschlechtlicher Beziehungen) käme einer Art „Verehrung von Regeln“ gleich und wäre keineswegs wirklich ethisch.[^6]

Ähnliche Urteile gelten für hypothetische Fälle, in denen man irgendwie sicher weiß, dass eine normalerweise zuverlässige Regel in diesem speziellen Fall kontraproduktiv ist. In Extremfällen erkennen wir alle, dass man lügen oder ein Versprechen brechen sollte, wenn Leben auf dem Spiel stehen. In der Praxis ist es natürlich der beste Weg, langfristig gute Ergebnisse zu erzielen, wenn man sich an [vernünftige moralische Regeln und Tugenden hält](https://utilitarianism.net/utilitarianism-and-practical-ethics#respecting-commonsense-moral-norms) und gleichzeitig nach Möglichkeiten sucht, anderen zu helfen. (Es ist wichtig, die hypothetischen Urteile, die Utilitarismus in stilisierten Gedankenexperimenten anbietet, nicht mit [der praktischen Anleitung](/utilitarismus-als-handlungsgrundlage) zu verwechseln, die er im wirklichen Leben bietet.) Der springende Punkt ist, dass Utilitarismus eine scheinbar unschlagbare Antwort auf die Frage gibt, _was grundsätzlich wichtig ist_: der Schutz und die Förderung der Interessen aller empfindungsfähigen Wesen, um die Welt so gut wie möglich zu machen.

### Der Schleier des Nichtwissens

Der Mensch ist ein Meister der Selbsttäuschung und neigt dazu, seine Kognition von seinen Motiven beeinflussen zu lassen. Wenn etwas für uns persönlich von Vorteil ist, ist es allzu leicht, uns davon zu überzeugen, dass es in Ordnung sein muss. Wir lassen uns auch leichter von den Interessen auffallender oder sympathischer Individuen beeinflussen (zum Beispiel bevorzugen wir Welpen gegenüber Schweinen). Um solche Voreingenommenheiten zu korrigieren, kann es hilfreich sein, [Unparteilichkeit](/arten-des-utilitarismus/#unparteilichkeit-und-gleichberechtigte-ber%C3%BCcksichtigung-von-interessen) zu erzwingen, indem man sich vorstellt, dass man hinter einem „[Schleier des Nichtwissens](https://plato.stanford.edu/entries/original-position/)“ auf die Welt herabblickt. Dieser Schleier enthüllt die Fakten über die Lebensumstände jedes Einzelnen in der Gesellschaft — sein Einkommen, sein Glücksniveau, seine Vorlieben usw. — und die Auswirkungen, die jede Wahl auf jede Person hätte, während er das Wissen darüber verbirgt, _welches dieser Individuen man selbst ist_.[^7] Um gerechter zu bestimmen, was _idealerweise getan werden sollte_, können wir fragen, was jeder hinter diesem Schleier des Nichtwissens aus persönlichen Gründen vorziehen würde. Wenn es gleich wahrscheinlich ist, schlussendlich in die Lage irgendeiner Person auf der Welt zu gelangen, scheint es vernünftig, das allgemeine Wohlergehen zu maximieren, genau wie es der Utilitarismus vorschreibt.[^8]

Es ist eine interessante Frage, wie viel Gewicht wir den Urteilen beimessen sollten, die hinter dem Schleier aus Eigeninteresse gefällt werden würden. Das Gedankenexperiment mit dem Schleier des Nichtwissens soll verdeutlichen, dass der Utilitarismus die Interessen aller Beteiligten unvoreingenommen und gleich gewichtet. Das heißt, Utilitarismus ist genau das, wo wir angelangen, wenn wir _gegenüber allen wohltätig_ sind: Die bedachte Fürsorge, die umsichtige Menschen für ihre _eigenen_ Interessen hegen, wird auf alle ausgedehnt.[^9] Aber für diejenigen, die den [Welfarismus ablehnen](/utilitarismus-nahe-alternativen/#jenseits-des-welfarismus) und damit bestreiten, dass es nur auf _Interessen_ ankommt, mag dies zirkulär erscheinen.  Das Gedankenexperiment bezieht sich beispielsweise nicht auf die Frage, ob nicht-empfindungsfähiges Leben oder natürliche Schönheit einen intrinsischen Wert hat. Es beschränkt sich auf den Teilbereich der Moral, der sich mit dem befasst, _was wir einander schulden_, wobei dies nur jene Individuen einschließt, auf die sich unsere durch den Schleier verursachte Unsicherheit über unsere Identität erstreckt: vielleicht gegenwärtig existierende empfindungsfähige Wesen.[^10] Dementsprechend müssen alle Urteile, die auf der Grundlage des Schleiers der Unwissenheit gefällt werden, immer noch gegen das abgewogen werden, was wir den ausgeschlossenen Anderen (beispielsweise zukünftigen Generationen oder nicht-welfaristischen Werten) schulden.

Dennoch werden diese anderen Faktoren in vielen Kontexten nicht relevant sein, und die Frage, was wir moralisch tun sollten, wird sich auf die Frage reduzieren, wie wir uns gegenseitig behandeln sollten. Viele der tiefgreifendsten Meinungsverschiedenheiten zwischen Utilitaristen und ihren Kritikern betreffen genau diese Frage. Und der Schleier der Unwissenheit scheint hier von Bedeutung zu sein. Die Tatsache, dass eine bestimmte Handlung das ist, was _jeder Betroffene_ hinter dem Schleier der Unwissenheit _persönlich bevorzugen würde_, scheint die Behauptung der Kritiker zu entkräften, dass irgendjemand durch diese Handlung _schlecht behandelt_ wurde oder Grund hat, sich darüber zu beschweren.

### Ex ante Pareto

Eine _Pareto_-Verbesserung ist für einige Menschen besser und für niemanden schlechter. Wenn Ergebnisse unsicher sind, können wir stattdessen die mit einer Handlung verbundenen _Aussichten_ bewerten — die Bandbreite der möglichen Ergebnisse, gewichtet nach ihren Wahrscheinlichkeiten. Eine Aussicht kann als besser für jemanden bewertet werden, wenn sie einem [in Erwartung](/arten-des-utilitarismus/#erwartungs-utilitarismus-versus-objektiver-utilitarismus) oder _ex ante_ ein größeres Wohlergehen bietet.[^11] Aus diesen Begriffen lässt sich der folgende Grundsatz ableiten:

**Ex ante Pareto:** Bei einer Wahl zwischen zwei Perspektiven ist die eine der anderen moralisch vorzuziehen, wenn sie für einige Personen bessere und für niemanden schlechtere Aussichten bietet.

Diese Brücke zwischen persönlichem Wert (oder Wohlergehen) und moralischer Bewertung wird im Aggregationstheorem des Ökonomen John Harsanyi weiterentwickelt.[^12] Aber der zugrunde liegende Gedanke, dass _vernünftige Wohltätigkeit_ von uns verlangt, _allen das Gute zu wünschen_ und Aussichten zu bevorzugen, die ex ante in _jedermanns_ Interesse liegen, wurde von Philosophen auch mit intuitiveren Begriffen verteidigt und weiterentwickelt.[^13]

Ein starker Einwand gegen die meisten nicht-utilitaristischen Ansichten ist, dass sie manchmal gegen ex ante Pareto verstoßen, zum Beispiel bei der Wahl von Maßnahmen hinter dem Schleier des Nichtwissens. Viele konkurrierende Ansichten implizieren absurderweise, dass Aussicht _Y_ moralisch vorteilhafter als Aussicht _X_ sein könnte, selbst wenn _Y_ für alle Beteiligten erwartungsgemäß schlechter ist.

Caspar Hare veranschaulicht dies mit einem Trolley-Problem, bei dem alle sechs möglichen Opfer in Koffern verstaut sind: Einer befindet sich auf einer Fußgängerbrücke, fünf sind auf den Gleisen darunter, und ein Zug wird alle fünf treffen und töten, es sei denn, man kippt den Koffer auf der Fußgängerbrücke um (in diesem Fall wird der Zug stattdessen diese eine Person töten und dann anhalten, bevor er die anderen erreicht).[^14] Da die Koffer erst kürzlich durcheinandergemischt wurden, weiß niemand, in welcher Position er sich befindet. Aus der Sicht _jedes_ Opfers sind seine Aussichten also am besten, wenn man den einen Koffer von der Fußgängerbrücke kippt, wodurch sich seine Überlebenschancen von 1/6 auf 5/6 erhöhen. In Anbetracht der Tatsache, dass dies ex ante im Interesse aller liegt, ist es sehr verwunderlich, dass es moralisch vorzuziehen wäre, diese einstimmige Präferenz, die von _allen_ Beteiligten geteilt wird, außer Kraft zu setzen und stattdessen fünf der sechs sterben zu lassen; dies ist jedoch eine Implikation der meisten nicht-utilitaristischen Ansichten.[^15]

### Erweiterung des moralischen Kreises

Wenn wir auf vergangene moralische Gräueltaten zurückblicken — wie die Sklaverei oder Frauen die Gleichberechtigung zu verweigern — erkennen wir, dass diese oft durch damals vorherrschende gesellschaftliche Normen gutgehießen wurden. Die Verursacher dieser Gräueltaten begingen einen schweren Fehler, als sie ihre Opfer aus dem „Kreis“ ihrer moralischen Betrachtungen ausschlossen.[^16] Das heißt, es war falsch, dass sie dem Leiden ihrer Opfer gegenüber gleichgültig waren (oder sich sogar daran erfreuten). Eine solche Ausgrenzung schien für die Menschen damals jedoch normal zu sein. Wir sollten uns also fragen, ob wir nicht auch blindlings einige Praktiken akzeptieren, die künftige Generationen als böse ansehen werden, die uns aber „normal“ erscheinen.[^17] Der beste Schutz davor, selbst einen solchen Fehler zu begehen, wäre, den Kreis unserer moralischen Betrachtung bewusst nach außen zu erweitern, um _alle_ fühlenden Wesen einzubeziehen — jeden, der leiden kann — und so zu erkennen, dass wir starke moralische Gründe haben, Leid zu verringern und Wohlergehen zu fördern, wo immer wir können, ganz gleich, _wer_ es ist, der es erfährt.

Diese Schlussfolgerung reicht zwar noch nicht bis zum vollständigen Utilitarismus, da sie beispielsweise mit der Annahme vereinbar ist, dass es Nebenbedingungen gibt, die das Streben nach dem Guten einschränken, aber sie reicht wahrscheinlich aus, um eine Übereinstimmung mit den wichtigsten [praktischen Implikationen des Utilitarismus](/utilitarismus-als-handlungsgrundlage) zu erzielen (die sich aus [Kosmopolitismus](https://utilitarianism.net/utilitarianism-and-practical-ethics#cosmopolitanism), [Antispeziesismus](https://utilitarianism.net/utilitarianism-and-practical-ethics#speciesism) und [Longtermism](/utilitarismus-und-praktische-ethik/#longtermism-den-moralischen-kreis-zeitlich-weiter-fassen) ergeben).

## Die Unzulänglichkeiten der Alternativen

Wir haben gesehen, dass es ein starkes Argument zugunsten des Utilitarismus gibt. Sollte sich keine konkurrierende Sichtweise als überlegen erweisen, so hat der Utilitarismus einen starken Anspruch darauf, die „Standard“-Theorie in der Moralphilosophie zu sein. Tatsächlich ist eine der stärksten Erwägungen zugunsten des Utilitarismus (und verwandter konsequentialistischer Ansichten) die Unzulänglichkeit der Alternativen. Insbesondere die deontologischen (oder regelbasierten) Theorien scheinen auf fragwürdigen Grundlagen zu beruhen.[^18]

Deontologische Theorien sind ausdrücklich _nicht-konsequentialistisch_: Anstatt Handlungen anhand ihrer Folgen moralisch zu bewerten, neigen diese Theorien dazu, bestimmte Arten von Handlungen (wie die Tötung einer unschuldigen Person) als _inhärent_ falsch anzusehen.[^19] Es gibt jedoch Gründe, an diesem ethischen Ansatz zu zweifeln.

### Das Paradoxon der Deontologie

Deontologen vertreten die Auffassung, dass es ein _Verbot_ des Tötens gibt: Es ist falsch, eine unschuldige Person zu töten, auch wenn dadurch fünf _andere_ unschuldige Personen vor dem Tod bewahrt werden. Dieses Urteil kann auf den ersten Blick rätselhaft erscheinen.[^20] Sollten wir angesichts der Tatsache, dass das Töten so schrecklich ist, nicht wollen, dass es _weniger_ davon gibt? Rationale Entscheidungen sind in der Regel zielgerichtet — eine Auffassung, die sich schlecht mit deontischen Zwängen verträgt.[^21] Ein Deontologe könnte behaupten, dass sein Ziel einfach darin besteht, _selbst_ keine moralischen Zwänge zu verletzen, was er am besten dadurch erreichen kann, dass er niemanden tötet, selbst wenn dies dazu führt, dass mehr Individuen getötet werden. Diese Erklärung kann deontologische Urteile zwar kohärent machen, aber um den Preis, dass sie furchtbar narzisstisch erscheinen, als ob es dem Deontologen nur darum ginge, seine eigene moralische Reinheit oder „saubere Hände“ zu bewahren.

Deontologen könnten sich gegen diese Charakterisierung wehren, indem sie stattdessen darauf bestehen, dass moralisches Handeln überhaupt nicht zielgerichtet sein muss.[^22] Anstatt nur danach zu streben, Werte zu fördern (oder Schaden zu minimieren), behaupten sie, dass moralisch Handelnde manchmal dazu aufgerufen sein können, den Wert eines anderen zu _respektieren_ (indem sie ihm nicht schaden, selbst als Mittel, um größeren Schaden für andere zu verhindern), was eine angemessen nach außen gerichtete, nicht narzisstische Motivation zu sein scheint.

Schefflers Herausforderung besteht darin, dass ein solcher Vorschlag moralische Normen auf rätselhafte Weise von anderen Arten praktischer Normen abweichen lässt. Wenn die Moral manchmal verlangt, Werte zu respektieren, statt sie zu fördern, warum gilt das dann nicht auch für die Klugheit? (In Anbetracht der Tatsache, dass Schmerzen schlecht für Menschen sind, wäre es zum Beispiel unklug, eine schmerzhafte Operation jetzt zu verweigern, wenn die Verweigerung dazu führt, dass man sich in Zukunft fünf vergleichbar schmerzhaften Operationen unterziehen muss). Deontologen mögen auf diese Frage verschiedene Antworten geben, aber insofern wir dazu neigen, von vornherein davon auszugehen, dass Ethik mit anderen Formen rationaler Entscheidungen in Einklang stehen sollte, gibt uns das einen Grund, konsequentialistische Darstellungen zu bevorzugen.

### Der Hoffnungs-Einwand

Unparteiische Beobachter sollten das beste Ergebnis anstreben und erhoffen. Nicht-Konsequentialisten behaupten, dass es dennoch manchmal falsch ist, das beste Ergebnis herbeizuführen. Wenn man die beiden Behauptungen zusammennimmt, kommt man zu dem erstaunlichen Ergebnis, dass man manchmal hoffen sollte, dass andere falsch handeln.

Angenommen, es wäre falsch, wenn ein Fremder — nennen wir ihn Jack — eine unschuldige Person tötet, um fünf andere (moralisch vergleichbare) Tötungen zu verhindern. Nicht-Konsequentialisten könnten behaupten, dass Jack eine besondere Verantwortung hat, dafür zu sorgen, dass _er_ niemanden tötet, selbst wenn dies zu weiteren Tötungen durch andere führt. Aber _du_ bist nicht Jack. Aus deiner Perspektive als unparteiischer Beobachter ist Jacks Tötung einer unschuldigen Person nicht mehr oder weniger schlecht als jede der fünf anderen Tötungen, die dadurch verhindert würden. Du hast allen Grund zu hoffen, dass es nur einen Mord gibt und nicht fünf. Du hast also Grund zu der Hoffnung, dass Jack „falsch“ handelt (einen tötet, um fünf zu retten). Etwas daran scheint seltsam zu sein.

Nicht nur ist es seltsam, sondern könnte sogar als Untergrabung der Behauptung verstanden werden, dass deontische Einschränkungen _zählen_ oder dass es wirklich _wichtig_ ist, sie einzuhalten. Schließlich heißt wichtig zu sein, dass es es wert ist, sich darum zu sorgen. Wir sollten uns zum Beispiel darum sorgen, wenn andere geschädigt werden, was die Behauptung bestätigt, dass die Interessen anderer moralisch wichtig sind. Wenn es uns aber nicht wichtiger ist, dass Jack sich an das moralische Verbot des Tötens hält, als dass er fünf Leben rettet, dann scheint das darauf hinzudeuten, dass das Verbot des Tötens moralisch _nicht_ wichtiger ist als die Rettung von fünf Leben.

Da sich unsere moralischen Verpflichtungen an dem orientieren sollten, was wirklich moralisch wichtig ist, können wir nicht verpflichtet sein, uns an deontische Zwänge zu halten, wenn diese nicht tatsächlich wichtig sind.[^23] Wir können nicht verpflichtet sein, deontischen Zwängen Vorrang vor dem Leben anderer zu geben, wenn wir uns mehr um das Leben anderer kümmern sollten als um deontische Zwänge. Deontische Zwänge können demnach unsere Verpflichtungen nicht genau beschreiben. Jack sollte wirklich das tun, was insgesamt das meiste Gute bewirkt. Wir sollten das auch.

### Skepsis gegenüber der Unterscheidung zwischen Tun und Erlauben

Man könnte sich fragen: Wenn der Respekt vor anderen erfordert, dass man ihnen nicht schadet (selbst wenn man anderen mehr helfen will), warum erfordert er dann nicht auch, dass man nicht _zulässt_, dass sie geschädigt werden? Deontologische Moraltheorien legen großen Wert auf Unterscheidungen wie die zwischen [Schaden zufügen und Schaden zulassen](https://utilitarianism.net/utilitarianism-and-practical-ethics#is-there-a-difference-between-doing-and-allowing-harm), zwischen Töten und Sterbenlassen oder zwischen beabsichtigtem und lediglich vorhergesehenem Schaden. Aber _warum_ sollten diese so unterschiedlich behandelt werden? Wenn ein Opfer in beiden Fällen gleich tot ist, scheint es für ihn keinen großen Unterschied zu machen, ob er getötet wurde oder sein Sterben „lediglich“ zugelassen wurde — was für ihn zählt, ist sicherlich sein Tod.

In der Tat ist es alles andere als klar, dass es eine belastbare Unterscheidung zwischen „tun“ und „erlauben“ _gibt_. Manchmal kann man etwas „tun“, indem man ganz ruhig bleibt.[^24] Auch wenn ein Arzt einen Patienten im Endstadium von den lebenserhaltenden Maschinen abtrennt, wird dies in der Regel als „sterben lassen“ betrachtet; wenn sich jedoch ein Mafioso aus Sorge um die möglicherweise belastende Aussage eines Informanten ins Krankenhaus schleicht und die lebenserhaltenden Geräte des Informanten abtrennt, ist es wahrscheinlicher, dass wir dies als „Tötung“ betrachten.[^25] Bennett (1998) argumentiert ausführlich, dass es keine befriedigende, völlig allgemeine Unterscheidung zwischen Tun und Lassen gibt — zumindest keine, die die moralische Bedeutung rechtfertigen würde, die Deontologen einer solchen Unterscheidung zuschreiben wollen.[^26] Wenn Bennett Recht hat, dann könnte uns das stattdessen zu einer Form des Konsequentialismus (wie dem Utilitarismus) zwingen.

### Status Quo-Voreingenommenheit

Die Ablehnung utilitaristischer Trade-Offs — das heißt die Begünstigung einiger zu geringeren Kosten für andere — läuft wohl auf eine Art Status-quo-Voreingenommenheit hinaus, die der _Erhaltung von Privilegien_ Vorrang vor der Förderung des Wohlergehens im Allgemeinen einräumt.

Ein solcher Konservatismus könnte auf den Irrtum der gerechten Welt zurückzuführen sein: der Fehler, davon auszugehen, dass der Status quo gerecht ist und dass die Menschen natürlicherweise das bekommen, was sie verdienen. Natürlich bietet die Realität keine solchen Gerechtigkeitsgarantien. In welche Umstände man hineingeboren wird, hängt nur vom Glück ab, einschließlich der körperlichen und kognitiven Fähigkeiten, die den Weg für künftigen Erfolg oder Misserfolg ebnen können. So gelingt es uns auch im späteren Leben nie, die Kontrolle über die Launen des Schicksals vollständig an uns zu reißen. Infolgedessen geht es manchen Menschen weitaus besser als anderen, obwohl sie das nicht verdienen. Warum sollten wir in solchen Fällen nicht bereit sein, einer Person zu einem geringeren Preis für privilegierte andere Personen zu helfen? Sie haben keinen besonderen Anspruch auf das zusätzliche Wohlergehen, das ihnen das Schicksal beschert hat.[^27] Natürlich ist es gut, wenn es Menschen gut geht und wir möchten niemandem unnötig schaden.[^28] Wenn wir jedoch das allgemeine Wohlergehen steigern können, indem wir einer Person zu geringeren Kosten für eine andere zugute kommen, sollten wir dies nicht allein aufgrund einer Voreingenommenheit zugunsten der bestehenden Verteilung unterlassen.[^29] Es ist leicht einzusehen, warum die traditionellen Eliten eine „Moral“ fördern wollen, die ihre festgefahrenen Interessen begünstigt. Weniger klar ist, warum sich andere einer solch verzerrten Sichtweise dessen, was (und wer) zählt, anschließen sollten.

In ähnlicher Weise kann argumentiert werden, dass es keinen wirklichen Unterschied zwischen der Auferlegung von Schäden und der Vorenthaltung von Vorteilen gibt. Der einzige Unterschied zwischen den beiden Fällen betrifft das, was wir als den Status quo verstehen, der keine moralische Bedeutung hat. Angenommen, Szenario A ist für jemanden besser als B. Dann wäre ein Wechsel von A zu B ein „Schaden“, während das Verhindern eines Wechsels von B zu A ein „Vorenthalten eines Nutzens“ wäre. Dies ist jedoch lediglich ein deskriptiver Unterschied. Wenn wir bestreiten, dass der historisch gegebene Ausgangspunkt eine moralisch privilegierte Ausgangsbasis darstellt, dann müssen wir sagen, dass die Kosten in beiden Fällen dieselben sind, nämlich der Unterschied im Wohlergehen zwischen A und B. Im Prinzip sollte es keine Rolle spielen, von wo wir starten.[^30]

Nehmen wir nun an, dass Szenario B für eine andere Person wesentlich besser ist als A: Vielleicht rettet sie ihr Leben, allerdings auf Kosten des Arms der ersten Person. Niemand würde es für in Ordnung halten, einen Menschen zu töten, nur um den Arm eines anderen zu retten (also um von B zu A zu wechseln). Wenn wir also eine Voreingenommenheit zugunsten des Status quo vermeiden wollen, müssen wir in ähnlicher Weise urteilen, dass es falsch wäre, sich der Verlagerung von A nach B zu _widersetzen_ — das heißt, wir sollten nichts dagegen haben, das Leben eines Menschen auf Kosten des Arms eines anderen zu retten.[^31] Wir sollten uns nicht besonders darum kümmern, das Privileg desjenigen zu bewahren, der von der Verlagerung profitieren würde; ein solcher Konservatismus ist nicht wahrhaft fair oder gerecht. Stattdessen sollte es unser Ziel sein, das beste _Gesamt_ergebnis zu erzielen, das alle gleichermaßen berücksichtigt, so wie es der Utilitarismus vorschreibt.

### Evolutionäre Entlarvungsargumente

Gegenüber diesen starken theoretischen Einwänden spricht für deontologische Theorien vor allem, dass sie mit unseren Intuitionen zu bestimmten Fällen besser übereinstimmen. Wenn diese Intuitionen jedoch nicht durch unabhängig plausible Prinzipien gestützt werden können, kann dies ihre Kraft untergraben — oder nahelegen, dass wir diese Intuitionen als gute Faustregeln zur praktischen Orientierung interpretieren sollten, anstatt sie als Hinweis darauf zu verstehen, worauf es _im Wesentlichen_ ankommt.

Die Kraft deontologischer Intuitionen kann auch untergraben werden, wenn nachgewiesen werden kann, dass sie aus einem unzuverlässigen Prozess resultieren. So mag die Evolution uns mit einer emotionalen Voreingenommenheit ausgestattet haben, die diejenigen bevorzugt, die so aussehen, sprechen und sich so verhalten wie wir selbst; dies bietet jedoch keine Rechtfertigung für die Diskriminierung von Menschen, die anders sind als wir selbst. Die Evolution ist ein blinder, amoralischer Prozess, dessen einziges „Ziel“ die Weitergabe von Genen ist, nicht die Förderung des Wohlergehens oder der moralischen Richtigkeit. Unsere moralischen Intuitionen müssen überprüft werden, insbesondere in Szenarien, die sich stark von unserem evolutionären Umfeld unterscheiden. Wenn wir feststellen, dass eine moralische Intuition auf unsere evolutionäre Herkunft zurückzuführen ist, können wir beschließen, ihr in unserer moralischen Argumentation kein großes Gewicht beizumessen — die Praxis der _evolutionären Entlarvungsargumente_.[^32]

Katarzyna de Lazari-Radek und Peter Singer argumentieren, dass Ansichten, die eine Parteilichkeit zulassen, besonders anfällig für evolutionäre Entlarvungsargumente sind, während [unparteiische](https://utilitarianism.net/types-of-utilitarianism#impartiality) Ansichten wie der Utilitarismus eher das Ergebnis unverzerrter Argumentation sind.[^33] Joshua Greene bietet ein anderes psychologisches Entlarvungsargument. Er argumentiert, dass deontologische Urteile — z. B. als Reaktion auf [Trolley-Fälle](https://de.wikipedia.org/wiki/Trolley-Problem) — tendenziell auf unzuverlässigen und widersprüchlichen emotionalen Reaktionen beruhen, einschließlich unserer Bevorzugung identifizierbarer gegenüber gesichtslosen Opfern und unserer Abneigung dagegen, jemandem aus der Nähe und nicht aus der Ferne zu schaden. Im Gegensatz dazu beinhalten utilitaristische Urteile die bewusste Anwendung allgemein anerkannter moralischer Grundsätze.[^34]

Solche entlarvenden Argumente werfen die Frage auf, ob sie nicht „zu viel beweisen“: Schließlich scheint das grundlegende moralische Urteil, dass _Schmerz schlecht ist_, selbst emotional aufgeladen und anfällig für evolutionäre Erklärungen zu sein — schließlich hätten körperlich verletzliche Lebewesen starke evolutionäre Gründe, Schmerzen vermeiden zu wollen, _ob sie nun objektiv schlecht sind oder nicht_!

Entlarvende Argumente sind jedoch am ehesten in Fällen anwendbar, in denen wir den Eindruck haben, dass es an einer prinzipiellen Erklärung für die Wahrheit des Urteils mangelt. Wir neigen nicht dazu, einen solchen Mangel in Bezug auf die Schlechtigkeit von Schmerz zu empfinden — wenn irgendwas ein in sich plausibles Urteil ist, dann sicher das. Manche Intuitionen können _überdeterminiert_ sein: Sie lassen sich _sowohl_ durch evolutionäre Ursachen _als auch_ durch ihre rationalen Vorzüge erklären. In einem solchen Fall müssen wir nicht davon ausgehen, dass die evolutionäre Erklärung das Urteil untergräbt, weil das Urteil _auch_ aus einem zuverlässigen Prozess (nämlich der Rationalität) resultiert. Im Gegensatz dazu sind deontologische Prinzipien und Parteilichkeit weit weniger _selbstevident_ gerechtfertigt und können daher als anfälliger für eine Entlarvung angesehen werden. Sobald wir eine Erklärung für diese psychologischen Intuitionen haben, die erklären kann, warum wir sie auch dann haben würden, wenn sie rational unbegründet wären, können wir eher zu dem Schluss kommen, dass sie tatsächlich rational unbegründet sind.

Daher ist es unwahrscheinlich, dass Entlarvungs-Einwände die Meinung einer Person ändern, die sich zu der angestrebten Ansicht hingezogen fühlt (oder sie als unabhängig gerechtfertigt und vertretbar betrachtet). Sie können jedoch dazu beitragen, die Zweifel derjenigen zu bestätigen, die bereits Grund zur Skepsis gegenüber den intrinsischen Vorzügen der Zielvorstellung hatten.

## Konklusion

Utilitarismus kann durch mehrere theoretische Argumente gestützt werden, wobei das stärkste vielleicht seine Fähigkeit ist, zu erfassen, _worauf es im Wesentlichen ankommt_. Seine Hauptkonkurrenten hingegen scheinen sich auf zweifelhafte Unterscheidungen — wie „tun“ vs. „erlauben“ — und eine eingebaute Voreingenommenheit zugunsten des Status quo zu stützen. Zumindest sieht es so aus, wenn man einem utilitaristischen Ansatz weitgehend zugeneigt ist. Angesichts der Flexibilität, die dem reflexiven Gleichgewicht innewohnt, ist es unwahrscheinlich, dass diese Argumente einen überzeugten Gegner dieser Sichtweise umstimmen. Wir hoffen, dass dieses Kapitel denjenigen Lesern, die den utilitaristischen Ansatz in der Ethik als zutiefst unsympathisch empfinden, zumindest helfen kann, besser zu verstehen, welchen Reiz _andere_ in dieser Sichtweise sehen.

Wie überzeugend man die Argumente für den Utilitarismus auch finden mag, ein endgültiges Urteil über diese Theorie wird auch davon abhängen, wie gut sie [die einflussreichen Einwände ihrer Kritiker entkräften](/einwande) kann.

Das nächste Kapitel befasst sich mit Theorien über Wohlergehen, das heißt mit der Frage, was für den Einzelnen als gut zählt.

{{< next-page-textbook >}}

---

{{< how-to-cite >}}

{{< button >}}

---

## Ressourcen und weiterführende Lektüre

* John Broome (1987). [Utilitarianism and Expected Utility](https://doi.org/10.2307/2026999), _The Journal of Philosophy_ 84 (8): 405–422.
* John Broome (1991). _Weighing Goods: Equality, Uncertainty and Time_. Blackwell.
* Krister Bykvist (2010). _[Utilitarianism: A Guide for the Perplexed](https://www.bloomsbury.com/us/utilitarianism-a-guide-for-the-perplexed-9780826498090/)_. Continuum.
* Robert Goodin (1995). _[Utilitarianism as a Public Philosophy](https://www.cambridge.org/core/books/utilitarianism-as-a-public-philosophy/DFAF4F0BDBA6B06F9BCB1DDC3D0A26A7)_. Cambridge University Press.
* Caspar Hare (2016). [Should We Wish Well to All?](https://dx.doi.org/10.1215/00318108-3624764), _Philosophical Review_ 125(4): 451–472.
* John C. Harsanyi (1955). [Cardinal Welfare, Individualistic Ethics, and Interpersonal Comparisons of Utility](https://www.jstor.org/stable/1827128), _The Journal of Political Economy_ 63 (4): 309–321.
* John C. Harsanyi (1977). _Rational Behavior and Bargaining Equilibrium in Games and Social Situations_. Cambridge University Press.
* Katarzyna de Lazari-Radek & Peter Singer (2017). Kapitel 2: Justifications, in _[Utilitarianism: A Very Short Introduction](https://global.oup.com/academic/product/utilitarianism-a-very-short-introduction-9780198728795)_. Oxford University Press.
* J.J.C. Smart (1973). An outline of a system of utilitarian ethics, in J.J.C. Smart & Bernard Williams, _[Utilitarianism: For and Against](https://www.cambridge.org/core/books/abs/utilitarianism/an-outline-of-a-system-of-utilitarian-ethics/8DE8362FF43188D53C855A70C70223E2)_. Cambridge University Press.

[^1]:
     Das soll nicht heißen, dass beide Antworten gleich gut oder richtig sind, sondern nur, dass man damit rechnen sollte, dass es schwierig sein wird, diejenigen zu überzeugen, die auf die Konflikte anders reagieren als man selbst.

[^2]:
     Natürlich kann es Ausnahmesituationen geben, in denen Stehlen insgesamt von Vorteil und daher gerechtfertigt ist, zum Beispiel wenn ein Laib Brot gestohlen werden muss, um das Leben eines Hungernden zu retten.

[^3]:
     Dabei ist es wichtig, neben den offensichtlichen direkten Kosten für das Opfer auch die indirekten Kosten zu berücksichtigen, die durch die Verringerung des sozialen Vertrauens entstehen.

[^4]:
     Vergleiche unsere Verteidigung des Aggregationsprinzips in [Kapitel 2](https://utilitarianism.net/types-of-utilitarianism#aggregationism), aus der hervorgeht, dass es in der Praxis fast jeder befürwortet, dass ausreichend viele kleine Vorteile für viele große Kosten für einige wenige aufwiegen können: „Wenn man beispielsweise zulässt, dass Autos auf den Straßen zu schnell fahren, steigt die Zahl der Menschen, die bei Unfällen sterben. Die Einführung extrem niedriger Geschwindigkeitsbegrenzungen würde Menschenleben retten, allerdings um den Preis, dass sie vielen Fahrern Unannehmlichkeiten bereiten. Die meisten Menschen zeigen ein implizites Bekenntnis zum Aggregationsprinzip, indem sie es für schlimmer halten, diese vielen Unannehmlichkeiten zu verursachen, um ein paar Leben zu retten.“
    Siehe auch Goodin, R. (1995). _Utilitarianism as a Public Philosophy_. Cambridge University Press.

[^5]:
     Peter Singer argumentiert in diesem Zusammenhang, dass „wir sehr schnell zu einer anfänglichen Präferenz-utilitaristischen Position gelangen, wenn wir den universellen Aspekt von Ethik auf einfache, prä-ethische Entscheidungsfindung anwenden.“ (p. 14)
    Singer, P. (2011). _Practical Ethics_, 3. Ed. Cambridge University Press.

[^6]:
     Smart, J.J.C. (1956). Extreme and restricted utilitarianism. _The Philosophical Quarterly_, 6(25): 344–354.

[^7]:
     Das Gedankenexperiment des „Schleiers des Nichtwissens“ wurde ursprünglich von Vickrey und Harsanyi entwickelt, obwohl es heutzutage eher mit John Rawls in Verbindung gebracht wird, der den Begriff prägte und das Gedankenexperiment abwandelte, um zu anderen Schlussfolgerungen zu gelangen. Rawls berief sich insbesondere auf eine Version, in der man zusätzlich die relativen Wahrscheinlichkeiten, in verschiedenen Positionen zu gelangen, nicht kennt, um utilitaristische Implikationen zu blockieren und stattdessen für eine „Maximin“-Position zu argumentieren, die der Steigerung des Wohlergehens des am schlechtesten Gestellten lexikalische Priorität einräumt.
    Vickrey, W. (1945). Measuring Marginal Utility by Reactions to Risk. _Econometrica_, 13(4): 329.
    Harsanyi, J.C. (1953). Cardinal Utility in Welfare Economics and in the Theory of Risk-taking. _Journal of Political Economy_, 61(5): 434–435.
    Rawls, J. (1971). _A Theory of Justice_. Belknap Press.

[^8]:
     Harsanyi formulierte sein Argument für Utilitarismus in Harsanyi, J. (1978). [Bayesian Decision Theory and Utilitarian Ethics](http://www.jstor.org/stable/1816692). _The American Economic Review_, 68(2): 223–228.
    Für eine Diskussion seines Beweises, siehe Greaves, H. (2017). [A Reconsideration of the Harsanyi–Sen–Weymark Debate on Utilitarianism](https://www.cambridge.org/core/journals/utilitas/article/reconsideration-of-the-harsanyisenweymark-debate-on-utilitarianism/45B191ED9B7BE4ACF598B49A74DCDF0E). _Utilitas_, 29(2): 175–213.

[^9]:
     Caspar Hare (2016). [Should We Wish Well to All?](https://dx.doi.org/10.1215/00318108-3624764) _Philosophical Review_, 125(4): 451–472.

[^10]:
     Zum Beispiel ist es bekanntermaßen unklar, wie man den Schleier des Nichtwissens  in der [Populationsethik](/populationsethik) auf Fälle mit unterschiedlichen Bevölkerungszahlen anwenden kann. Wenn die Person, die sich hinter dem Schleier verbirgt, garantiert existiert, würde dies natürlich die [Durchschnittsansicht](/populationsethik/#die-durchschnittsansicht) nahelegen. Wenn es sich jedoch um eine lediglich mögliche Person handelt, die daher einen Anreiz hat, mehr (glückliche) Leben zu wollen, um zu existieren, würde dies eher für die [Gesamtansicht](/populationsethik/#die-gesamtansicht) sprechen.

[^11]:
    _Ex post_-Interessen hingegen betreffen die tatsächlichen Ergebnisse, die sich daraus ergeben. Interessanterweise können Theorien Bewertungen von Wohlergehen _ex post_ mit einem breiteren „erwartungsbezogenen“ Element kombinieren. So misst der _ex post_-[Prioritarismus](/utilitarismus-nahe-alternativen/#prioritarismus) beispielsweise der Vermeidung schlechter _Ergebnisse_ (statt schlechter _Aussichten_) für die am schlechtesten gestellten Personen einen zusätzlichen sozialen Wert bei, kann aber dennoch Aussichten anhand ihres _erwarteten sozialen Werts_ bewerten.

[^12]:
     Harsanyi (1955, pp. 312-314; 1977, pp. 64-68), in der Neuinterpretation von John Broome (1987, pp. 410-411; 1991, pp. 165, 202-209). Weitere Erklärungen sind in unserem Gastbeitrag über formale Argumente für den Utilitarismus von Johan E. Gustafsson und Kacper Kowalczyk, der demnächst auf <www.utilitarianism.net/guest-essays/> erscheinen wird, zu finden.

[^13]:
     Zum Beispiel: Hare, C. (2016). [Should We Wish Well to All?](https://dx.doi.org/10.1215/00318108-3624764) _Philosophical Review_, 125(4): 451–472.

[^14]:
     Hare, C. (2016). [Should We Wish Well to All?](https://dx.doi.org/10.1215/00318108-3624764) _Philosophical Review_, 125(4): 451–472, pp. 454–455.

[^15]:
     Hare (2016) erörtert die Gründe einiger Philosophen für ihre Skepsis gegenüber der moralischen Bedeutung der _ex ante Rechtfertigbarkeit für alle_ und untermauert das Prinzip mit weiteren Argumenten ausgehend von _mutmaßlicher Zustimmung_, _schmutzigen Händen_ und _Komposition_.

[^16]:
     Singer, P. (2011). _[The Expanding Circle: Ethics, Evolution, and Moral Progress](https://press.princeton.edu/books/paperback/9780691150697/the-expanding-circle)_. Princeton University Press.

[^17]:
     Vgl. Williams, E. G. (2015). [The Possibility of an Ongoing Moral Catastrophe](https://link.springer.com/article/10.1007/s10677-015-9567-7). _Ethical Theory and Moral Practice_, 18(5): 971–982.

[^18]:
     Die folgenden Argumente sollten auch gegen tugendethische Ansätze gelten, sofern sie zu nicht-konsequentialistischen Urteilen darüber führen, welche _Handlungen_ ausgeführt werden sollten.

[^19]:
     Strenge, absolute Deontologen vertreten die Auffassung, dass solche Urteile _völlig unabhängig von den Konsequenzen_ gelten. Gemäßigte Deontologen hingegen halten die identifizierten Handlungen für _präsumptiv_ falsch und nicht _leicht_ aufzuwiegen, lassen aber zu, dass dies aufgewogen werden kann, wenn _ausreichend_ viel Wert auf dem Spiel steht. So könnte ein gemäßigter Deontologe beispielsweise anerkennen, dass es zulässig ist, zu lügen, um das Leben eines anderen zu retten, oder dass es zulässig ist, einen Unschuldigen zu töten, um eine Million zu retten.

[^20]:
     Samuel Scheffler stellte fest, dass „so oder so jemand verliert: eine unverletzliche Person wird verletzt. Warum ist es nicht wenigstens zulässig, die Verletzung von fünf Personen zu verhindern, indem man eine verletzt?“ (p. 88)
    Scheffler, S. (1994). _The Rejection of Consequentialism_, überarbeitete Ausgabe. Oxford University Press.

[^21]:
     Scheffler, S. (1985). [Agent-Centred Restrictions, Rationality, and the Virtues](https://dx.doi.org/10.1093/mind/XCIV.375.409). _Mind_, 94(375): 409–19.

[^22]:
     Siehe z. B. Chappell, T. (2011). [Intuition, System, and the “Paradox” of Deontology](https://doi.org/10.1017/CBO9780511973789.013). In Jost, L. & Wuerth, J. (Hrsg.), _Perfecting Virtue: New Essays on Kantian Ethics and Virtue Ethics_. Cambridge University Press, pp. 271–88.

[^23]:
     Es steht dem Deontologen frei, darauf zu bestehen, dass es _für Jack_ wichtiger sein sollte, auch wenn es für niemand anderen wichtig ist. Dies verstößt jedoch gegen die verlockende Vorstellung, dass der moralische Standpunkt unparteiisch ist und zu Urteilen führt, denen vernünftige Beobachter (und nicht nur der Handelnde selbst) zustimmen könnten.

[^24]:
     Man könnte zum Beispiel seinen Ehepartner in die Irre führen, indem man sich in der Tarnung versteckt hält, obwohl er hätte schwören können, dass man gerade bei ihm im Zimmer war. Oder wie Foot (1978, 26) meint: „Ein Schauspieler, der nicht zu einer Aufführung erscheint, wird sie im Allgemeinen eher verderben, als dass er zulässt, dass sie verdorben wird“.
    Foot, P. (1978). The Problem of Abortion and the Doctrine of the Double Effect. In _Virtues and Vices and Other Essays_. University of California Press.

[^25]:
     Beauchamp, T. (2020). Justifying Physician-Assisted Deaths. In LaFollette, H. (Hrsg.), _Ethics in Practice: An Anthology_ (5. Ed.), pp. 78–85.

[^26]:
     Bennett, J. (1998). _[The Act Itself](https://oxford.universitypressscholarship.com/view/10.1093/019823791X.001.0001/acprof-9780198237914)_. Oxford University Press.

[^27]:
     In ähnlicher Weise schrieb Derek Parfit: „Einige von uns fragen, wie viel von unserem Reichtum wir Reichen den Ärmsten geben sollten. Aber diese Frage setzt fälschlicherweise voraus, dass unser Reichtum uns gehört, um ihn zu geben. Dieser Reichtum gehört rechtlich uns. Aber diese ärmsten Menschen haben viel stärkere moralische Ansprüche auf einen Teil dieses Reichtums. Wir sollten diesen Menschen ... mindestens zehn Prozent dessen, was wir verdienen, zukommen lassen.“
    Parfit, D. (2017). _On What Matters, Volume Thre_e. Oxford University Press, pp. 436-37.

[^28]:
     Zum Thema des Opferns schrieb John Stuart Mill: „Die utilitaristische Moral erkennt im Menschen die Fähigkeit an, sein eigenes höchstes Gut für das Wohl anderer zu opfern. Sie weigert sich nur, zuzugeben, dass das Opfer selbst ein Gut ist. Ein Opfer, das die Gesamtsumme des Glücks nicht erhöht oder dazu tendiert, sie zu erhöhen, betrachtet sie als verschwendet.“
    Mill, J. S. (1863). [Kapitel 2: What Utilitarianism Is](https://utilitarianism.net/books/utilitarianism-john-stuart-mill/2), _Utilitarianism_.

[^29]:
     Das bedeutet jedoch nicht, dass Utilitarismus nach perfekter Gleichheit der Verteilung materieller Güter oder gar des Wohlergehens strebt. Joshua Greene stellt fest:„[E]ine Welt, in der jeder das Gleiche erhält, egal was er tut, ist eine untätige Welt, in der Menschen wenig Anreiz haben, etwas zu tun. Der Weg zur Maximierung des Glücks besteht also nicht darin, zu dekretieren, dass jeder gleich glücklich sein soll, sondern darin, Menschen zu einem Verhalten zu ermutigen, das das Glück maximiert. Wenn wir unseren moralischen Erfolg messen, zählen wir das Glück aller gleichermaßen, aber das Erreichen von Erfolg ist fast sicher mit einer Ungleichheit sowohl beim materiellen Wohlstand als auch beim Glück verbunden. Eine solche Ungleichheit ist nicht ideal, aber sie wird damit gerechtfertigt, dass die Welt ohne sie insgesamt schlechter wäre.“
    Greene, J. (2013). _[Moral Tribes: Emotion, Reason, and the Gap Between Us and Them](https://www.joshua-greene.net/moral-tribes)_. Penguin Press, p. 163. Siehe auch: [The Equality Objection to Utilitarianism](/einwande/gleichheit).

[^30]:
     In der Praxis bedeutet das psychologische Phänomen der _Verlustaversion_, dass jemand sich durch etwas, das er als „Verlust“ empfindet, _aufgebrachter_ fühlt als durch einen bloßen „entgangenen Gewinn“. Solche negativen Gefühle können das Wohlergehen weiter mindern und das Urteil „Verlust ist schlimmer“ zu einer Art sich selbst erfüllender Prophezeiung machen. Dies hängt jedoch von kontingenten psychologischen Phänomenen ab, die _zusätzlichen_ Schaden verursachen; es ist nicht so, dass der Verlust _an sich_ schlechter ist.

[^31]:
     Bostrom, N. & Ord, T. (2006). [The Reversal Test: Eliminating Status Quo Bias in Applied Ethics](https://dx.doi.org/10.1086/505233). _Ethics_, 116(4): 656–679.

[^32]:
     Es gibt auch andere Arten von Entlarvungsargumenten, die nicht auf der Evolution beruhen. Man bedenke, dass das Christentum in den meisten westlichen Gesellschaften über mehr als tausend Jahre lang die vorherrschende Religion war, was erklärt, warum moralische Intuitionen, die auf der christlichen Moral beruhen, immer noch weit verbreitet sind. Beispielsweise haben viele gläubige Christen starke moralische Intuitionen in Bezug auf Geschlechtsverkehr, die Nichtchristen in der Regel nicht teilen, wie etwa die Intuition, dass es falsch ist, vor der Ehe Sex zu haben, oder dass es falsch ist, wenn zwei Männer Sex haben. Im akademischen Diskurs der Moralphilosophie werden solche religiös bedingten moralischen Intuitionen im Allgemeinen außer Acht gelassen. Viele Philosophen, einschließlich der meisten Utilitaristen, würden daher christlichen Intuitionen in Bezug auf Geschlechtsverkehr kein großes Gewicht beimessen.

[^33]:
     de Lazari-Radek, K. & Singer, P. (2012). [The Objectivity of Ethics and the Unity of Practical Reason](https://dx.doi.org/10.1086/667837). _Ethics,_ 123(1): 9–31.

[^34]:
     Greene, J. (2007). [The secret joke of Kant’s soul](https://doi.org/10.7551/mitpress/7504.003.0004). In Sinnott-Armstrong, W. (Hrsg.), _Moral Psychology, Vol. 3_. MIT Press.
