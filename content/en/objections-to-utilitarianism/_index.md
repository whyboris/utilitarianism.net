---
title: "Objections to Utilitarianism and Responses"
date: 2023-01-29
draft: false
menu: ["objections", "main"]
weight: 300
page: 0
description: "This chapter presents a toolkit of general strategies for responding to objections to utilitarianism, before introducing the most influential specific objections to the theory."
gradientTop: "#1F2A70"
gradientBottom: "#1F1E70"
---

> _"Bernard Williams... concluded a lengthy attack on utilitarianism by remarking: ‘The day cannot be too far off in which we hear no more of it.’ It is now more than forty years since Williams made that comment, but we continue to hear plenty about utilitarianism."_ \
> \- Katarzyna de Lazari-Radek & [Peter Singer](/utilitarian-thinker/peter-singer)[^1]

{{< TOC >}}

Utilitarianism is a very controversial moral theory. Critics have raised many objections against it, and its defenders have responded with attempts to defuse these objections.

While our presentation focuses on utilitarianism, it is worth noting that many of the objections below could also be taken to challenge [other forms of consequentialism](/near-utilitarian-alternatives) (just as many of the [arguments for utilitarianism](/arguments-for-utilitarianism/) also apply to these related views). This chapter explores objections to utilitarianism and closely related views in contrast to non-consequentialist approaches to ethics.

## General Ways of Responding to Objections to Utilitarianism

Many objections rest on the idea that utilitarianism has counterintuitive implications. We can see these implications by considering concrete examples or _thought experiments_. For instance, in our article on the [rights objection](/objections-to-utilitarianism/rights), we consider the Transplant case:

> **Transplant:** Imagine a hypothetical scenario in which there are five patients, each of whom will soon die unless they receive an appropriate transplanted organ⁠—a heart, two kidneys, a liver, and lungs. A healthy patient, Chuck, comes into the hospital for a routine check-up and the doctor finds that Chuck is a perfect match as a donor for all five patients. Should the doctor kill Chuck and use his organs to save the five others?

At first glance, it seems that utilitarianism has to answer the question affirmatively. It is better that five people survive than that just one person does. But killing Chuck seems morally monstrous to many. This apparent implication of utilitarianism is taken as an argument against its being the correct moral theory.

Proponents of utilitarianism can respond to its apparent counterintuitive implications in four general ways.

First, they can _accommodate_ the intuition that seems to conflict with utilitarianism by arguing that a sophisticated application of utilitarian principles avoids the counterintuitive implication. To more reliably promote good outcomes, sophisticated utilitarians recognize their cognitive limitations and [act in accordance with commonsense norms and heuristics](/utilitarianism-and-practical-ethics/#respecting-commonsense-moral-norms), other than in exceptional circumstances. Insofar as an objector merely claims that we should embrace or oppose certain norms _in practice_, utilitarians can often straightforwardly agree.

Second, utilitarians can attempt to _debunk the moral intuition_ invoked by a particular case by suggesting that it resulted from an unreliable process.[^2] If a [debunking argument](/arguments-for-utilitarianism#evolutionary-debunking-arguments) succeeds, the targeted moral intuition should not be given much weight in our moral reasoning.

Third, proponents of utilitarianism can _attack the available alternatives_—such as deontological or virtue ethical theories—to show that they have [implications no less counterintuitive than those of utilitarianism](/arguments-for-utilitarianism#the-poverty-of-the-alternatives).

A fourth strategy is to _tolerate_ the intuition, which is sometimes called “biting the bullet”. This is to accept that utilitarianism has counterintuitive implications but to hold on to the theory because all-things-considered it is still more plausible than its rivals. The costs of accepting a counterintuitive implication, it is argued, can be outweighed by the force of [the arguments in favor of utilitarianism](/arguments-for-utilitarianism). Moreover, our intuitions are often inconsistent and they are subject to change over time, which makes it impossible to find consistent and plausible principles that reflect all of them. So it requires good judgment to determine which intuitions and theoretical commitments are non-negotiable, and which we should be willing to compromise on in pursuit of “[reflective equilibrium](/arguments-for-utilitarianism#introduction-moral-methodology-amp-reflective-equilibrium)”, or the most plausible and coherent overall combination of moral verdicts and principles.

## The Utilitarian’s Toolkit

There are further ideas that utilitarians may appeal to in developing the above general strategies.

- _Keep hypotheticals at a distance_.[^2a] The distinction between utilitarianism’s [_criterion of rightness_ and its _recommended decision procedure_](/types-of-utilitarianism#multi-level-utilitarianism-versus-single-level-utilitarianism) is crucial to utilitarian attempts to _accommodate_ common intuitions. Given that [“rightness” is not the central concept of utilitarian theory](/types-of-utilitarianism/#reconstructing-rightness-maximizing-satisficing-and-scalar-utilitarianism), it may well make more sense to interpret common intuitions about “right” and “wrong” as addressing the question of what norms we (as fallible agents) should endorse in practice, rather than what ideally ought to be done (by an omniscient being) in principle. If justified, this interpretive move can drastically reduce the apparent conflict between utilitarianism and commonsense moral intuitions.

- _Accommodate nearby intuitions_. More generally, utilitarians may seek to reduce their apparent conflict with commonsense by identifying _nearby_ intuitions that they _can_ accommodate. For example, if critics claim that a specific welfare-maximizing action is intuitively _wrong_, utilitarians may argue that our intuition here is better thought of tracking one of the following features:

  - that it would be good to _inculcate practical norms_ against actions of that type;
  - that a person willing to perform such an action would likely have _bad character_, and be likely to cause greater harms on other occasions;
  - that the action is _reckless_, or plausibly wrong _in expectation_, even if it happens to turn out for the best.[^3]

- _Gobble up competing values_. Critics sometimes allege that utilitarians don’t value obviously good things like rights, freedom, virtue, equality, and the natural environment. But while these things may be obviously good, it is less obvious that they are all _non-instrumentally_ good. And utilitarians can certainly value them instrumentally. Moreover, utilitarians who accept an [objective list theory of well-being](/theories-of-wellbeing/#objective-list-theories) may even be able to give non-instrumental consideration to goods (like freedom and [beauty](/near-utilitarian-alternatives/#aesthetic-value)) that could plausibly be counted as welfare goods when part of a person’s life.

- _Stuff people into suitcases_. Rival moral theories may be undermined by appeal to the [veil of ignorance](/arguments-for-utilitarianism#the-veil-of-ignorance), and the related idea of _[ex ante Pareto](/arguments-for-utilitarianism/#ex-ante-pareto)_—or what it would be in _everyone_’s best interests to agree to in advance (before learning about their particular position in life). Our intuitive reluctance to stick with the overall best policy can then start to seem [biased](/arguments-for-utilitarianism/#status-quo-bias). To make the point vivid, when faced with difficult trade-offs between conflicting interests, just imagine putting each affected person in a separate suitcase, and shuffling their positions.[^3a] All would then rationally endorse the utilitarian-recommended action.

- _The Pluralist’s Dilemma_ (between extremism and arbitrariness). If you hold that there are non-utilitarian moral reasons (e.g. deontic constraints) that sometimes outweigh utilitarian reasons, this raises tricky questions about how the two kinds of reasons compare. If the non-utilitarian reason always trumps—no matter how great the cost to overall well-being—then this seems implausibly extreme. But the “moderate” pluralist alternative risks arbitrariness, due to lacking a clear account of where to draw the line, or precisely how much weight to give to non-utilitarian reasons relative to utilitarian ones.[^4]

- _Bang the drums of war_. We live in a _morally unusual world_. During high-stakes emergencies like fighting a just war, many activities that would otherwise seem [above and beyond the call of duty](/utilitarianism-and-practical-ethics/#demandingness), or even wrong, may instead be morally required—including risking your life, imposing burdens on your loved ones and leaving them for years, and killing enemy combatants. But in fact our “ordinary circumstances” involve horrific amounts of [preventable suffering](/acting-on-utilitarianism#opportunities-to-help-others), with stakes as high as any war. Utilitarian verdicts may thus be bolstered by noting that much sentient life is (metaphorically) under siege, and that some moral heroism may accordingly be required to set things right.[^5]

- _Make winning distinctions_. [Different versions](/types-of-utilitarianism/) of utilitarianism may be more or less vulnerable to different objections. For example, a version of the view that combines [scalar](/types-of-utilitarianism/#reconstructing-rightness-maximizing-satisficing-and-scalar-utilitarianism), [expectational](/types-of-utilitarianism/#expectational-utilitarianism-versus-objective-utilitarianism), and [hybrid](/types-of-utilitarianism/#global-utilitarianism-and-hybrid-utilitarianism) elements may be better equipped to mitigate concerns about demandingness, cluelessness, and praiseworthy motivations. Objections to specifically [hedonistic](/theories-of-wellbeing/#hedonism) utilitarianism (such as the Experience Machine and Evil Pleasures objections) do not apply to utilitarians who accept a different [theory of well-being](/theories-of-wellbeing/).

Despite the silly labels, these are serious philosophical moves. We employ each, where appropriate, to respond to the specific objections listed below. (Students are encouraged, when reading an objection, to anticipate how to apply the utilitarian’s toolkit to address the objection at hand.)

## Specific Objections to Utilitarianism

In separate articles, we discuss the following critiques of utilitarianism:

{{< textbook-objections >}}

{{< next-page-objection hide-other="true" >}}

{{< how-to-cite >}}

{{< button >}}

## Resources and Further Reading

- Katarzyna de Lazari-Radek & Peter Singer (2017). _[Utilitarianism: A Very Short Introduction](https://global.oup.com/academic/product/utilitarianism-a-very-short-introduction-9780198728795)_. Oxford: Oxford University Press. Chapter 4: Objections.
- J. J. C. Smart & Bernard Williams (1973). _Utilitarianism: For and Against_. Cambridge: Cambridge University Press.

[^1]: de Lazari-Radek, K. & Singer, P. (2017). _[Utilitarianism: A Very Short Introduction](https://global.oup.com/academic/product/utilitarianism-a-very-short-introduction-9780198728795)_. Oxford: Oxford University Press. Preface.
[^2]: For a discussion of evolutionary debunking arguments, see Hanson, R. (2002). [Why Health Is Not Special: Errors In Evolved Bioethics Intuitions](http://mason.gmu.edu/~rhanson/bioerr.pdf). _Social Philosophy & Policy_. 19(2): 153–79. See also the discussion in our chapter on the [Arguments for Utilitarianism](/arguments-for-utilitarianism#evolutionary-debunking-arguments).
[^2a]: Public health experts recommend maintaining social distance of 6 feet or more from silly hypothetical cases at all times, lest they [infect](/objections-to-utilitarianism/abusability/) your understanding of [what utilitarianism actually calls for in practice](/acting-on-utilitarianism/). If closer contact is required, protect yourself and others by first reading up on [the utilitarian case for respecting commonsense norms](/utilitarianism-and-practical-ethics/#respecting-commonsense-moral-norms), explained in Chapter 6.
[^3]: As further explained in our article on the [rights objection](/objections-to-utilitarianism/rights), standard “counterexamples” to utilitarianism invite us to imagine that a typically-disastrous class of action (such as killing an innocent person) just so happens, in this special case, to produce the best outcome. But the agent in the imagined case generally has no good basis for discounting the typical risk of disaster. So it would be unacceptably risky for them to perform the typically-disastrous act. We maximize expected value by avoiding such risks. For all practical purposes, utilitarianism recommends that we should refrain from rights-violating behaviors. This constitutes a generalizable defense of utilitarianism against a wide range of alleged counterexamples.
[^3a]: Hare, C. (2016). [Should We Wish Well to All?](http://dx.doi.org/10.1215/00318108-3624764) _Philosophical Review_, 125(4): 451–472, pp. 454–455. See also the discussion in our chapter on the [Arguments for Utilitarianism](/arguments-for-utilitarianism/#ex-ante-pareto).
[^4]: By contrast, utilitarianism offers a clear and principled account of (e.g.) when constraints can reasonably be violated—namely, just when doing so would truly best serve overall well-being. Similarly for when it is worth damaging the natural environment, how to weigh small harms to many against grave harms to a few, and so on. That’s not to say that it will always be easy to _tell_ what utilitarianism recommends in real-life situations, since it can be difficult to predict future outcomes. But it is at least clear _in principle_ how different considerations weigh against each other, whereas other theories often do not offer even this much clarity.
[^5]: Of course, that’s not to suggest that the same particular actions are called for. Adopting a "war-like" stance outside of war might be expected to prove counterproductive. The point is just that the stakes are high enough that we shouldn’t necessarily expect truly moral advice, in our circumstances, to be _comfortable_.
