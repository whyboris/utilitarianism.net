---
title: "Argumentos a favor del utilitarismo"
slug: "argumentos-a-favor-del-utilitarismo"
authors: "Chappell, R.Y. y Meissner, D."
date: 2023-01-29
draft: false
menu: "main"
weight: 103
description: "Este capítulo explica el equilibrio reflexivo como metodología moral y presenta varios argumentos a favor del utilitarismo respecto de los enfoques morales no consecuencialistas."
gradientTop: "#012147"
gradientBottom: "#084BC7"
---

{{< TOC >}}

## Introducción: metodología moral y equilibrio reflexivo

Nadie puede _probar_ una teoría moral. Como respuesta a los argumentos que se ofrezcan, se puede siempre rechazar alguna de sus premisas, si se está dispuesto a aceptar los costos de hacerlo. Diferentes teorías ofrecen diferentes ventajas. En este capítulo se exponen algunas de las consideraciones más importantes a favor del utilitarismo. Una perspectiva completa debe considerar también los costos del utilitarismo (o las ventajas de sus competidores), lo que se aborda en el capítulo [Objeciones al utilitarismo](/objeciones). Se podrá entonces decidir qué teoría moral parece la mejor o la más plausible en términos generales.

Para ello, los filósofos morales suelen emplear la metodología del _equilibrio reflexivo_,[^1] que consiste en equilibrar dos grandes tipos de evidencia aplicada a las teorías morales:

1. Intuiciones sobre casos específicos (experimentos mentales).
2. Consideraciones teóricas generales, incluida la plausibilidad de los _principios_ de la teoría o afirmaciones sistemáticas sobre lo que importa moralmente.

Los principios generales pueden cuestionarse presentando presuntos _contraejemplos_, o casos en los que los principios arrojan un veredicto intuitivamente incorrecto. En respuesta a esos presuntos contraejemplos, debemos comparar la fuerza de la intuición basada en el caso con la plausibilidad inherente del principio cuestionado. Esto podría llevarnos _o bien_ a revisar el principio para adaptarlo a nuestras intuiciones sobre los casos _o bien_ a reconsiderar nuestro veredicto sobre el caso concreto, si consideramos que el principio general está mejor fundamentado (especialmente si somos capaces de "explicar" que la intuición contraria se basa en algún error o confusión implícita).

Como veremos, los argumentos a favor del utilitarismo descansan abrumadoramente en consideraciones teóricas generales. [Los cuestionamientos a la teoría](/objeciones al utilitarismo) pueden adoptar cualquier forma, pero muchas de las objeciones más serias tienen que ver con experimentos mentales en los que se sostiene que el utilitarismo produce veredictos contrarios a la intuición.

No hay una respuesta neutra, que no implique tomar partido, a cómo se deben resolver esos conflictos.[^2] Hace falta tener criterio, y personas diferentes pueden tener una disposición a reaccionar de manera diferente dependiendo de su temperamento filosófico. Por regla general, las personas con un temperamento que favorece la _teorización sistemática_ se sienten más atraídas por el utilitarismo ([y perspectivas afines](/alternativas-cercanas-al-utilitarismo/)), mientras que quienes se aferran a las intuiciones del sentido común son menos propensos a dejarse influir por sus virtudes teóricas. De modo que considerar los argumentos que se exponen a continuación puede hacer algo más que arrojar luz sobre el utilitarismo; también puede ayudar al lector a discernir su propio temperamento filosófico.

Aunque nuestra presentación se centra en el utilitarismo, vale la pena señalar que muchos de los argumentos que se exponen a continuación también podrían utilizarse para apoyar [otras formas de consecuencialismo bienestarista](/alternativas-cercanas-al-utilitarismo/) (del mismo modo que muchas de las [objeciones al utilitarismo](/objeciones) también se aplican a estos puntos de vista relacionados). Este capítulo explora los argumentos a favor del utilitarismo y los puntos de vista estrechamente relacionados frente a los enfoques morales no consecuencialistas.

## Argumentos a favor del utilitarismo

### Lo que importa fundamentalmente

Las teorías morales sirven para especificar _lo que importa fundamentalmente_, y el utilitarismo ofrece una respuesta particularmente convincente a esta pregunta.

Casi todo el mundo estaría de acuerdo con el utilitarismo en que el sufrimiento es malo y el [bienestar](/teorias-del-bienestar/) es bueno. ¿Qué podría ser más obvio? Si algo importa moralmente, sin duda es el bienestar humano. Y sería [arbitrario limitar](https://altruismoeficaz.net/temas/especismo) la preocupación moral a nuestra propia especie, por lo que deberíamos concluir que lo que importa es el bienestar en general. Es decir, deberíamos querer que las vidas de los seres sintientes fueran lo mejor posible (ya sea maximizando la [felicidad](/teorias-del-bienestar#hedonismo), la [satisfacción del deseo](/teorias-del-bienestar#teorias-del-deseo) u [otros elementos constitutivos del bienestar](/teorias-del-bienestar#teorias-de-la-lista-objetiva)).

¿Podría haber algo _más_ importante? Tal sugerencia puede parecer desconcertante. Por ejemplo, robar (normalmente) está mal,[^3] pero es plausible que así sea porque robar tiende a ser _perjudicial_, ya que reduce el bienestar de las personas.[^4] En cambio, la mayoría de la gente está dispuesta a pagar impuestos redistributivos si permiten a los gobiernos proporcionar beneficios que aumenten de forma fiable el nivel general de bienestar de la sociedad. Por tanto, no es que los individuos tengan un derecho natural a no ser molestados pase lo que pase. A la hora de juzgar los acuerdos institucionales (como la propiedad y la legislación fiscal), reconocemos que lo que importa es llegar a acuerdos que tiendan a garantizar _buenos resultados generales_, y que el factor más importante para que un resultado sea _bueno_ es que _promueva el bienestar_.[^5]

Este razonamiento puede justificar que se considere el utilitarismo como el punto de partida por defecto de la teorización moral.[^6] Si alguien quiere afirmar que hay alguna otra consideración moral que puede prevalecer sobre el _bienestar general_ (superando la importancia de salvar vidas, reducir el sufrimiento y promover la prosperidad), se enfrenta al desafío de explicar _cómo_ podría ser así. Muchas normas morales comunes (como las que prohíben robar, mentir o romper promesas), aunque no son explícitamente utilitaristas en su contenido, tienen sin embargo un claro fundamento utilitarista. Si en general no promovieran el bienestar, sino que perjudicaran activamente a la gente, es difícil ver qué razón tendríamos para seguir queriendo que se las respete. Respetar y hacer cumplir normas morales _perjudiciales_ (como las que prohíben las relaciones sentimentales entre personas del mismo sexo) parecería una especie de "culto a las normas", y no sería realmente nada ético.[^7]

Juicios similares se aplican a casos hipotéticos en los que, de algún modo, se sabe con certeza que una norma generalmente fiable es, en este caso concreto, contraproducente. En el caso extremo, todos reconocemos que se debe mentir o romper una promesa si hay vidas en juego. En la práctica, por supuesto, la mejor forma de conseguir buenos resultados a largo plazo es [respetar las normas y las virtudes de la moral de sentido común](/utilitarismo-y-etica-practica#respetar-las-normas-de-sentido-comun) al tiempo que se buscan oportunidades para ayudar a los demás. (Es importante no confundir los veredictos hipotéticos que ofrece el utilitarismo en experimentos mentales simplificados con [la orientación práctica que ofrece en la vida real](/actuar-conforme-al-utilitarismo/).) El punto clave es sólo que el utilitarismo ofrece una respuesta aparentemente imbatible a la pregunta de _lo que importa fundamentalmente_: proteger y promover los intereses de todos los seres sintientes para hacer el mundo tan bueno como sea posible.

### El velo de la ignorancia

Los humanos somos maestros del autoengaño y el razonamiento motivado. Si algo nos beneficia personalmente, es muy fácil convencernos de que debe estar bien. También nos dejamos influir más fácilmente por los intereses de los individuos que más se destacan o despiertan más simpatía (favorecer a los cachorros en lugar de a los cerdos, por ejemplo). Para corregir esos prejuicios, puede ser útil forzar la [imparcialidad](/elementos-y-tipos-de-utilitarismo#imparcialidad-e-igual-consideración-de-intereses) imaginando que se observa el mundo por detrás de un “[velo de la ignorancia](https://es.wikipedia.org/wiki/Posici%C3%B3n_original)”. Este velo revela los hechos acerca de las circunstancias de cada individuo en la sociedad —sus ingresos, su nivel de felicidad, sus preferencias, etc.— y los efectos que cada elección tendría sobre cada persona, al tiempo que impide conocer _cuál de estos individuos uno es_.[^8] Para determinar de forma más justa _lo que idealmente debería hacerse_, podemos preguntarnos qué es lo que cada uno tendría más razones personales para preferir por detrás de este velo de la ignorancia. Si uno tuviera las mismas probabilidades de acabar siendo cualquiera en el mundo, parecería prudente maximizar el bienestar general, tal y como prescribe el utilitarismo.[^9]

Es una pregunta interesante la de cuánto peso debemos dar a los veredictos que se elegirían, por interés personal, por detrás del velo. El experimento mental del velo sirve para resaltar cómo el utilitarismo da el mismo peso a los intereses de todos, de forma imparcial. Es decir, el utilitarismo es precisamente lo que obtenemos cuando somos _benéficos con todos_: extendiendo a todo el mundo el tipo de preocupación cuidadosa que la gente prudente tiene por sus _propios_ intereses.[^10] Pero puede parecer cuestionable para quienes [rechazan el bienestarismo](/alternativas-cercanas-al-utilitarismo#mas-all-del-bienestarismo), y niegan así que los _intereses_ sean lo único que importa. Por ejemplo, el experimento del velo claramente no se refiere a la cuestión de si la vida no sintiente o la belleza natural tienen valor intrínseco. Está restringido al subdominio de la moralidad que concierne a _lo que nos debemos los unos a los otros_, el cual incluye sólo a aquellos individuos que abarca la incertidumbre sobre nuestra identidad inducida por el velo: los seres sintientes que hoy existen, quizás.[^11] En consecuencia, cualquier veredicto alcanzado sobre la base del velo de la ignorancia tendrá que ser sopesado con lo que todavía podríamos deber a cualquier otro factor excluido (como las generaciones futuras o los valores no bienestaristas).

Aun así, en muchos contextos estos otros factores no serán relevantes, y la cuestión de lo que moralmente debemos hacer se reducirá a la cuestión de cómo debemos tratarnos los unos a los otros. Muchos de los desacuerdos más profundos entre los utilitaristas y sus críticos se refieren precisamente a esta cuestión. Y el velo de la ignorancia parece relevante aquí. El hecho de que alguna acción sea la que _todos los afectados preferirían personalmente_ por detrás del velo de la ignorancia parece socavar las afirmaciones de los críticos de que algún individuo ha sido _maltratado_ por esa acción o tiene motivos para quejarse de ella.

### Pareto _ex ante_

Una mejora Pareto es mejor para algunas personas y peor para ninguna. Cuando los resultados son inciertos, podemos evaluar la _perspectiva_ asociada a una acción: el abanico de posibles resultados, ponderados por la probabilidad de cada uno. Se puede considerar que una perspectiva es mejor para una persona cuando le ofrece un mayor bienestar [en términos esperados](/elementos-y-tipos-de-utilitarismo#utilitarismo-expectacional-versus-utilitarismo-objetivo), o _ex ante_.[^12] Uniendo estos conceptos, podemos formular el siguiente principio:

> **Pareto _ex ante_:** en una elección entre dos perspectivas, una es moralmente preferible a otra si constituye una perspectiva mejor para algunas personas y una perspectiva peor para ninguna.

Este puente entre el valor (o bienestar) personal y la evaluación moral se desarrolla en el teorema de la agregación del economista John Harsanyi,[^13] pero la idea subyacente, que la _beneficencia razonable_ requiere que _deseemos el bien para todos_ y prefiramos perspectivas que beneficien a _todos ex ante_, también ha sido defendida y desarrollada en términos más intuitivos por algunos filósofos.[^14]

Una poderosa objeción a la mayoría de los puntos de vista no utilitaristas es que a veces violan Pareto _ex ante_, como cuando se eligen políticas por detrás del velo de la ignorancia. Muchos puntos de vista rivales implican, absurdamente, que la perspectiva _Y_ podría ser moralmente preferible a la perspectiva _X_, incluso cuando _Y_ es peor en términos esperados para todos los involucrados.

Caspar Hare ilustra la cuestión con un problema del tranvía en el que las seis víctimas posibles están dentro de maletas: una está encima de un puente peatonal, cinco están en las vías de abajo, y un tren atropellará y matará a las cinco a menos que se empuje a la que está en el puente (en cuyo caso el tren matará a ésta y se detendrá antes de alcanzar a las demás).[^15] Como las maletas se han distribuido al azar recientemente, nadie sabe en qué posición están. Así que, desde el punto de vista de _cada_ víctima, sus perspectivas son mejores si uno empuja la maleta en el puente, aumentando las probabilidades de sobrevivir de 1/6 a 5/6. Dado que esto beneficia a todos _ex ante_, es profundamente desconcertante pensar que sería moralmente preferible anular esta preferencia unánime, compartida por _todos_ los involucrados, y dejar morir a cinco de los seis; sin embargo, esa es la implicación de la mayoría de las teorías no utilitaristas.[^16]

### Ampliación del círculo moral

Cuando recordamos atrocidades morales del pasado —como la esclavitud o la negación de iguales derechos a las mujeres— reconocemos que a menudo estaban sancionadas por las normas sociales dominantes en aquel momento. Los autores de estas atrocidades se equivocaron gravemente al excluir a sus víctimas de su "círculo" de preocupación moral.[^17] Es decir, se equivocaron al mostrarse indiferentes ante el sufrimiento de sus víctimas (o incluso complacidos por él). Pero esa exclusión le parecía normal a la gente de la época. Así que deberíamos preguntarnos si no estaremos aceptando ciegamente algunas prácticas que las generaciones futuras considerarán inmorales, pero que a nosotros nos parecen "normales".[^18] La mejor protección para no cometer ese error sería ampliar deliberadamente nuestra preocupación moral para incluir a _todos_ los seres sintientes (cualquiera que pueda sufrir) y reconocer que tenemos razones morales de peso para reducir el sufrimiento y promover el bienestar siempre que podamos, sin importar _quién_ lo experimente.

Si bien esta conclusión no llega al utilitarismo pleno, ya que es compatible, por ejemplo, con la idea de que existen restricciones laterales que limitan la búsqueda del bien, probablemente sea suficiente para asegurar el acuerdo con las [implicaciones prácticas del utilitarismo](/actuar-conforme-al-utilitarismo/) más importantes (derivadas del [cosmopolitismo](/utilitarismo-y-etica-practica#cosmopolitismo), el [antiespecismo](/utilitarismo-y-etica-practica#especismo) y el [largoplacismo](/utilitarismo-y-etica-practica#largoplacismo)).

## La pobreza de las alternativas

Hemos visto que existe una fuerte presunción a favor del utilitarismo. Si no se puede demostrar que ningún punto de vista rival es superior, entonces el utilitarismo tiene una fuerte pretensión de ser la teoría moral "por defecto". De hecho, una de las consideraciones más sólidas a favor del utilitarismo (y de las perspectivas consecuencialistas afines) es la deficiencia de las alternativas. Las teorías deontológicas (o basadas en reglas), en particular, parecen descansar sobre fundamentos cuestionables.[^19]

Las teorías deontológicas son explícitamente _no consecuencialistas_: en lugar de valorar moralmente las acciones evaluando sus consecuencias, estas teorías tienden a considerar que ciertos tipos de acción (como matar a un inocente) son _intrínsecamente_ incorrectas.[^20] Sin embargo, hay razones para dudar de este enfoque de la ética.

### La paradoja de la deontología

Los deontólogos sostienen que existe una _restricción_ contra el asesinato: que está mal asesinar a una persona inocente incluso si esto salvara de ser asesinadas a otras cinco personas inocentes. Este veredicto puede parecer desconcertante a primera vista.[^21] Después de todo, dado lo terrible que es el asesinato, ¿no deberíamos querer que hubiera _menos_ asesinatos? En general, la elección racional tiende a estar dirigida a un objetivo: tal concepción encaja mal con las restricciones deónticas.[^22] Un deontólogo podría sostener que su objetivo es simplemente evitar violar _él mismo_ las restricciones morales, lo que puede conseguir mejor no asesinando a nadie, incluso si eso da lugar a más asesinatos. Aunque esta explicación puede dar coherencia a los veredictos deontológicos, lo hace a costa de hacerlos parecer terriblemente narcisistas, como si la preocupación central del deontólogo fuera sólo mantener su propia pureza moral o sus "manos limpias".

Los deontólogos podrían oponerse a esta caracterización insistiendo en que la acción moral no tiene por qué estar dirigida a un objetivo.[^23] En lugar de buscar únicamente promover el valor (o minimizar el daño), afirman que los agentes morales a veces deben _respetar_ el valor de otro (no haciéndole daño, incluso como medio para evitar un daño mayor a los demás), lo que parecería una motivación no narcisista, adecuadamente dirigida hacia el exterior.

El desafío de Scheffler sigue siendo que tal propuesta hace que las normas morales diverjan misteriosamente de otros tipos de normas prácticas. Si la moral a veces exige respetar el valor en lugar de promoverlo, ¿por qué no ocurre lo mismo con la prudencia? (Dado que el dolor es malo para uno, por ejemplo, no parecería prudente rechazar una operación dolorosa ahora si el rechazo le compromete a cinco operaciones comparativamente dolorosas en el futuro). Los deontólogos pueden ofrecer varias respuestas a esta pregunta, pero en la medida en que nos inclinemos a pensar, preteóricamente, que la ética debe formar un continuo con otras formas de elección racional, tendremos alguna razón para preferir los planteamientos consecuencialistas.

### La objeción de esperar lo incorrecto

Los observadores imparciales deben desear y esperar el mejor resultado. Los filósofos no consecuencialistas afirman que a veces, no obstante, es incorrecto hacer que se produzca el mejor resultado. Juntando ambas afirmaciones se obtiene la sorprendente conclusión de que a veces uno debería desear y esperar que otros actúen de modo incorrecto.

Supongamos que fuera incorrecto que un desconocido —llamémoslo Jack— asesinara a un inocente para evitar otros cinco asesinatos (moralmente comparables). Quienes se oponen al consecuencialismo pueden afirmar que _Jack_ tiene la responsabilidad especial de asegurarse de no matar a nadie, aunque esto provoque que otros cometan más asesinatos. Pero _tú_ no eres Jack. Desde tu perspectiva de observador imparcial, que Jack asesine a un inocente no es ni más ni menos intrínsecamente malo que cualquiera de los otros cinco asesinatos que ese acto evitaría. Tienes más razones para esperar un asesinato antes que cinco. Así que tienes razones para esperar que Jack actúe "incorrectamente" (matando a uno para salvar a cinco). Pero eso parece extraño.

Más que parecer extraño, podría incluso considerarse que socava la afirmación de que las restricciones deónticas _cuentan_, o que es genuinamente _importante_ respetarlas. Al fin y al cabo, "ser importante" no es más que "ser tal que debería importarnos". Por ejemplo, debería importarnos que otros sufran daños, lo que valida la afirmación de que los intereses de los demás son moralmente importantes. Pero si el respeto de Jack por la restricción moral de no matar no debe importarnos más que salvar cinco vidas, parece que la restricción de no matar no es moralmente más importante que salvar cinco vidas.

Por último, puesto que nuestras obligaciones morales deberían estar en consonancia con lo que es genuinamente importante desde el punto de vista moral, si las restricciones deónticas no son de hecho importantes, entonces no podemos estar obligados a respetarlas.[^24] No podemos estar obligados a dar prioridad a las restricciones deónticas por encima de la vida de los demás, si debemos preocuparnos más por la vida de los demás que por las restricciones deónticas. Así que, después de todo, las restricciones deónticas no deben describir con exactitud nuestras obligaciones. Jack realmente debería hacer lo que produjera el mayor bien total, y nosotros también.

### Escepticismo sobre la distinción entre hacer y permitir

Cabe preguntarse: si el respeto a los demás requiere no hacerles daño (incluso para ayudar más a otros), ¿por qué no requiere igualmente no _permitir_ que se les haga daño? Las teorías morales deontológicas conceden gran importancia a distinciones como las que existen entre [hacer daño y permitirlo](/utilitarismo-y-etica-practica#hay-diferencia-entre-hacer-daño-y-permitir-daño), o entre matar y dejar morir, o entre los daños intencionados y los meramente previstos. Pero, ¿_por qué_ deberían tratarse de forma tan diferentes? Si una víctima acaba igualmente muerta de cualquier forma, el hecho de que la mataran o "meramente" la dejaran morir no parece suponer una gran diferencia para ella; sin duda, lo que a ella le importa es simplemente su muerte.

De hecho, no está nada claro que exista una distinción clara entre "hacer" y "permitir". A veces se puede "hacer" algo permaneciendo totalmente inmóvil.[^25] Asimismo, cuando un médico desconecta a un paciente terminal de las máquinas de soporte vital, se suele considerar que está "dejando morir"; pero si un mafioso, preocupado por el testimonio potencialmente incriminatorio de un informante, se cuela en el hospital y desconecta su soporte vital, es más probable que consideremos que se trata un "asesinato".[^26] Bennett argumenta extensamente que no existe una distinción satisfactoria y totalmente general entre hacer y permitir, al menos ninguna que reivindique el significado moral que los deontólogos quieren atribuir a esa distinción.[^27] Si Bennett tiene razón, entonces eso podría obligarnos a adoptar en su lugar alguna forma de consecuencialismo (como el utilitarismo).

### Sesgo del _statu quo_

La oposición a las compensaciones utilitaristas —es decir, a las acciones que confieren beneficios a unos a expensas de imponer costos menores a otros— equivaldría a una especie de sesgo del _statu quo_, que da prioridad a _preservar los privilegios_ por sobre promover el bienestar en general.

Ese conservadurismo podría derivarse de la falacia del mundo justo: el error de suponer que el _statu quo_ es justo y que la gente obtiene naturalmente lo que merece. Por supuesto, la realidad no ofrece tales garantías de justicia. Las circunstancias en las que uno nace dependen de la suerte, incluida la dotación de capacidades físicas y cognitivas que pueden allanar el camino hacia el éxito o el fracaso en el futuro. Por eso, ni siquiera en la edad adulta conseguimos recuperar el control de los caprichos de la fortuna y, en consecuencia, algunas personas gozan de una situación mucho mejor que otras a pesar de no haber hecho nada para merecerlo. En tales casos, ¿por qué no habríamos de estar dispuestos a beneficiar a una persona a un costo menor incurrido por otras personas privilegiadas? Éstas no tienen ningún derecho especial al bienestar adicional que la fortuna les ha concedido.[^28] Está claro que es bueno que la gente goce de bienestar y, desde luego, no querríamos causar daños innecesarios a nadie.[^29] Sin embargo, si podemos aumentar el bienestar general beneficiando a una persona a un costo menor incurrido por otra, no deberíamos abstenernos de hacerlo simplemente por un prejuicio a favor de la distribución existente.[^30] Es fácil ver por qué las élites tradicionales querrían promover una "moralidad" que favoreciera sus intereses arraigados. No está tan claro por qué los demás deberían aceptar una visión tan distorsionada de qué (y quién) importa.

Del mismo modo, se puede argumentar que no existe una distinción real entre dañar y no beneficiar. La única diferencia entre ambos casos se refiere a lo que entendemos por _statu quo_, que carece de relevancia moral. Supongamos que el escenario A es mejor para alguien que el B. Entonces, cambiar de A a B sería una instancia de "dañar", mientras que impedir un cambio de B a A sería una instancia de "no beneficiar". Pero se trata de una diferencia meramente descriptiva. Si negamos que el punto de partida históricamente dado proporciona un punto de referencia moralmente privilegiado, entonces debemos decir que el costo en ambos casos es el mismo, a saber, la diferencia de bienestar entre A y B. En principio, no debería importar de dónde partimos.[^31]

Supongamos ahora que el escenario B es mucho mejor para otra persona que el A: quizá le salve la vida, a costa del brazo de la primera persona. A nadie le parecería bien matar a una persona sólo para salvar el brazo de otra (es decir, pasar de B a A). Por tanto, si queremos evitar el sesgo del _statu quo_, debemos juzgar, de modo similar, que sería incorrecto _oponerse_ al cambio de A a B; es decir, no deberíamos oponernos a salvar la vida de alguien a costa del brazo de otro.[^32] No deberíamos preocuparnos especialmente por preservar el privilegio de quien saliera beneficiado por defecto; ese conservadurismo no es realmente equitativo ni justo. En lugar de ello, nuestro objetivo debería ser conseguir el mejor resultado _en general_, contando a todos por igual, tal y como prescribe el utilitarismo.

### Argumentos genealógicos evolutivos

Frente a estas poderosas objeciones teóricas, la principal consideración que tienen a su favor las teorías deontológicas es una mayor conformidad con nuestras intuiciones sobre casos particulares. Pero si estas intuiciones no pueden apoyarse en principios independientemente plausibles, eso puede socavar su fuerza, o sugerir que deberíamos interpretar estas intuiciones como buenas reglas generales para la orientación práctica, y no como indicadores de lo que importa _fundamentalmente_.

La fuerza de las intuiciones deontológicas también puede verse mermada si se demuestra que resultan de un proceso poco confiable. Por ejemplo, los procesos evolutivos pueden habernos dotado de un sesgo emocional que favorezca a quienes se parecen, hablan y comportan como nosotros; sin embargo, esto no ofrece ninguna justificación para discriminar a quienes no se parecen a nosotros. La evolución es un proceso ciego y amoral cuyo único "objetivo" es la propagación de los genes, no la promoción del bienestar o la corrección moral. Nuestras intuiciones morales deben ser sometidas a examen, sobre todo en escenarios que difieren mucho de nuestro entorno evolutivo. Si identificamos una intuición moral como proveniente de nuestra ascendencia evolutiva, podemos decidir no darle mucha importancia en nuestro razonamiento moral: en esto consisten los _argumentos genealógicos evolutivos_.[^33]

Katarzyna de Lazari-Radek y Peter Singer sostienen que los teorías que permiten la parcialidad son especialmente vulnerables a estos argumentos, mientras que las teorías [imparciales](/elementos-y-tipos-de-utilitarismo#imparcialidad) como el utilitarismo tienen más probabilidades de ser el resultado de un razonamiento no distorsionado.[^34] Joshua Greene ofrece un argumento genealógico psicológico diferente. Sostiene que los juicios deontológicos —por ejemplo, en respuesta a los [problemas del tranvía](https://es.wikipedia.org/wiki/Dilema_del_tranv%C3%ADa)— suelen derivarse de respuestas emocionales poco fiables e incoherentes, incluido nuestro favoritismo por las víctimas identificables frente a las anónimas y nuestra aversión a dañar a alguien de cerca en lugar de hacerlo de lejos. En cambio, los juicios utilitaristas implican la aplicación más deliberada de principios morales ampliamente respetados.[^35]

Estos argumentos genealógicos suscitan la preocupación de si "prueban demasiado": después de todo, el juicio moral fundacional de que _el dolor es malo_ parecería en sí mismo cargado de emociones y susceptible de una explicación evolutiva. ¡Las criaturas físicamente vulnerables tendrían poderosas razones evolutivas para querer evitar el dolor _fuera o no_ objetivamente malo!

Sin embargo, los argumentos genealógicos podrían ser aplicables sobre todo en casos en los que creemos que falta una explicación fundada de la verdad del juicio. No solemos sentir tal carencia en lo que respecta a la maldad del dolor: se trata, sin duda, de un juicio intrínsecamente plausible, si hay algo que lo sea. Algunas intuiciones pueden estar _sobredeterminadas_: explicables _tanto_ por causas evolutivas _como_ por sus méritos racionales. En tal caso, no tenemos por qué considerar que la explicación evolutiva socava el juicio, porque el juicio _también_ resulta de un proceso fiable (a saber, la racionalidad). Por el contrario, los principios deontológicos y la parcialidad tienen una justificación mucho menos _evidente_, por lo que pueden considerarse más vulnerables al argumento genealógico. Una vez que disponemos de una explicación para estas intuiciones psicológicas que puede explicar por qué las tendríamos aunque carecieran de fundamento racional, parece que hay una mayor justificación para concluir que, en efecto, carecen de fundamento racional.

Por ello, es poco probable que los argumentos genealógicos hagan cambiar de opinión a quien se siente atraído por la teoría en cuestión (o la considera justificada y defendible de forma independiente). Pero pueden ayudar a confirmar las dudas de quienes ya pensaban que había motivos para el escepticismo respecto a los méritos intrínsecos de esa teoría.

## Conclusión

El utilitarismo puede apoyarse en varios argumentos teóricos, siendo quizá el más sólido su capacidad para capturar _lo que fundamentalmente importa_. Sus principales competidores, por el contrario, parecen basarse en distinciones dudosas —como las distinción entre "hacer" y "permitir"— y en el sesgo del _statu quo_. Al menos, así es como lo ven las personas que simpatizan con el enfoque utilitarista. Dada la flexibilidad inherente al equilibrio reflexivo, es poco probable que estos argumentos hagan cambiar de opinión a un opositor convencido. Para aquellos lectores que encuentren el enfoque utilitarista de la ética profundamente inaceptable, esperamos que este capítulo pueda al menos ayudarlos a comprender mejor el atractivo que _otros_ pueden ver en esta teoría.

Por muy sólidos que sean los argumentos a favor del utilitarismo, el veredicto final sobre la teoría dependerá también de su capacidad para rebatir [las influyentes objeciones que los críticos han formulado en su contra](/objeciones).

El siguiente capítulo analiza las teorías del bienestar, es decir, lo que se considera bueno para una persona.

{{< next-page-textbook >}}

---

{{< how-to-cite >}}

{{< button >}}

## Recursos y Más información

- {{< cite Broome1987UtilitarianismExpectedUtility >}}
- {{< cite Broome1991WeighingGoodsEquality >}}
- {{< cite Bykvist2010UtilitarianismGuidePerplexed >}}
- {{< cite Goodin1995UtilitarianismPublicPhilosophy >}}
- {{< cite Hare2016ShouldWeWish >}}
- {{< cite Harsanyi1955CardinalWelfareIndividualistic >}}
- {{< cite Harsanyi1977RationalBehaviorBargaining >}}
- {{< cite "Lazari-Radek2017Justification" >}}
- {{< cite Smart1961OutlineSystemUtilitarian >}}

[^1]: {{< cite Daniels2003ReflectiveEquilibrium >}}
[^2]: Esto no quiere decir que cualquier respuesta sea de hecho igualmente buena o correcta, sino que sólo deberíamos esperar que sea difícil _persuadir_ a quienes responden a los conflictos de un modo diferente al nuestro.
[^3]: Por supuesto, puede haber circunstancias excepcionales en las que robar sea beneficioso en general y, por tanto, esté justificado, por ejemplo, cuando sea necesario robar una barra de pan para salvar la vida de una persona hambrienta.
[^4]: Aquí es importante considerar los costos indirectos de reducir la confianza social, además de los evidentes costos directos para la víctima.
[^5]:
    Compárese nuestra defensa del agregacionismo en el [capítulo 2](/elementos-y-tipos-de-utilitarismo#agregacionismo), que muestra cómo, en la práctica, casi todo el mundo está a favor de permitir un número suficiente de pequeños beneficios para compensar los grandes costos de unos pocos: "Por ejemplo, permitir que los coches circulen rápido por las carreteras aumenta el número de personas que mueren en accidentes. Establecer límites de velocidad excesivamente bajos salvaría vidas a costa de incomodar a muchos conductores. La mayoría de la gente demuestra un compromiso implícito con el agregacionismo cuando juzga que es peor imponer muchas molestias de este tipo en aras de salvar unas pocas vidas."

    Véase también {{< cite Goodin1995UtilitarianismPublicPhilosophy >}}

[^6]:
    Peter Singer sostiene, en relación con lo anterior, que "llegamos rápidamente al utilitarismo de las preferencias como posición inicial una vez que el aspecto universal de la ética es aplicado a decisiones pre-éticas simples." ({{< cite Singer1993PracticalEthics "chap. 1" >}})
[^7]: {{< cite Smart1956ExtremeRestrictedUtilitarianism >}}
[^8]:
    El experimento mental del "velo de la ignorancia" fue desarrollado originalmente por Vickrey y Harsanyi, aunque hoy en día se asocia más a menudo con John Rawls, que acuñó el término y modificó el experimento para llegar a conclusiones diferentes. En concreto, Rawls apeló a una versión en la que además se ignoran las probabilidades relativas de acabar en varias posiciones, para bloquear las implicaciones utilitaristas y argumentar en su lugar a favor de una posición "maximin" que da prioridad léxica al aumento del bienestar de los más desfavorecidos.

    {{< cite Vickrey1945MeasuringMarginalUtility "p. 329" >}}

    {{< cite Harsanyi1953CardinalUtilityWelfare "pp. 434–435" >}}

    {{< cite Rawls1971TheoryJustice >}}

[^9]:
    Harsanyi formalizó sus argumentos a favor del utilitarismo en {{< cite Harsanyi1978BayesianDecisionTheory >}}

    Para una discusión sobre su prueba, véase {{< cite Greaves2017ReconsiderationHarsanyiSenWeymarkDebate >}}

[^10]: {{< cite Hare2016ShouldWeWish >}}

[^11]: Es notoriamente confuso cómo aplicar el velo de la ignorancia a casos de "números diferentes" en [ética de la población](/etica-de-la-poblacion/), por ejemplo. Si el agente detrás del velo va a existir indefectiblemente, esto sugeriría naturalmente [la perspectiva promedio](/etica-de-la-poblacion#la-perspectiva-promedio). Si fuera una persona meramente posible y, por tanto, tuviera algún incentivo para desear que existieran más vidas (felices), sugeriría [la perspectiva total](/etica-de-la-poblacion#la-perspectiva-total).

[^12]: Los intereses _ex post_, por el contrario, se refieren a los resultados reales que se obtienen. Curiosamente, las teorías pueden combinar las evaluaciones _ex post_ del bienestar con un elemento de "expectativa" más amplio. Por ejemplo, el [prioritarismo](/alternativas-cercanas-al-utilitarismo#prioritarismo) _ex post_ asigna un valor social adicional a evitar malos _resultados_ (en lugar de malas _perspectivas_) para los individuos en peor situación, pero puede seguir evaluando las perspectivas por su _valor social esperado_.

[^13]: {{< cite Harsanyi1955CardinalWelfareIndividualistic "pp. 312–314" >}}; {{< cite Harsanyi1977RationalBehaviorBargaining "pp. 64–68" >}}, reinterpretado por {{< cite Broome1987UtilitarianismExpectedUtility "pp. 410–411" >}}; {{< cite Broome1991WeighingGoodsEquality "pp. 165, 202–209" >}} Para más información, véase nuestro próximo ensayo invitado sobre los argumentos a favor del utilitarismo, de Johan E. Gustafsson y Kacper Kowalczyk, que aparecerá en <www.utilitarianism.net/guest-essays/>.

[^14]: Por ejemplo, {{< cite Hare2016ShouldWeWish >}}

[^15]: {{< cite Hare2016ShouldWeWish "pp. 454–455" >}}

[^16]: El artículo {{< cite -Hare2016ShouldWeWish >}} discute los motivos de escepticismo de algunos filósofos sobre el significado moral de la _justificabilidad ex ante para todos_, y apoya el principio con argumentos adicionales de _consentimiento presunto_, _manos sucias_ y _composición_.

[^17]: {{< cite Singer2011ExpandingCircleEthics >}}
[^18]: {{< cite Williams2015PossibilityOngoingMoral >}}

[^19]: Los siguientes argumentos también deberían aplicarse contra los enfoques de la ética de la virtud, si producen veredictos no consecuencialistas sobre qué _actos_ deben realizarse.
[^20]: Los deontólogos absolutistas sostienen que tales juicios se aplican _sin importar las consecuencias_. Los deontólogos moderados, en cambio, consideran que las acciones identificadas son _presuntamente_ incorrectas y no se compensan _fácilmente_, pero permiten que esto se compense si está en juego una cantidad _suficiente_ de valor. Así, por ejemplo, un deontólogo moderado podría permitir que se mintiera para salvar la vida de alguien, o que se matara a un inocente para salvar a un millón.
[^21]:
    Samuel Scheffler señaló que "de cualquier manera, alguien pierde: se vulnera a alguna persona que no debe ser vulnerada. ¿Por qué no es al menos permisible evitar que se vulnere a cinco personas vulnerando a una?" ({{< cite Scheffler1994RejectionConsequentialismPhilosophical "p. 88" >}})

[^22]: {{< cite Scheffler1985AgentcentredRestrictionsRationality >}}
[^23]: {{< cite Chappell2011IntuitionSystemAnd >}}
[^24]: El deontólogo puede insistir en que debería ser más importante _para Jack_, aunque no lo sea para nadie más. Pero esto se opone a la idea atractiva de que el punto de vista moral es imparcial y capaz de producir veredictos sobre los que observadores razonables (y no sólo el propio agente) podrían estar de acuerdo.
[^25]:
    Por ejemplo, podrías inquietar a tu cónyuge permaneciendo oculto en un camuflaje, cuando hubiera jurado que estabas en la habitación haciéndole compañía. O, como sugiere Foot ({{< cite Foot1967ProblemAbortionDoctrine "p. 26" >}}): "Un actor que no se presenta a una representación normalmente la arruinará, en lugar de permitir que se arruine."

[^26]: {{< cite Beauchamp2020JustifyingPhysicianAssisted >}}
[^27]: {{< cite Bennett1995ActItself >}}
[^28]:
    En una línea similar, Derek Parfit escribió que "Algunos nos preguntamos qué parte de nuestra riqueza debemos dar los ricos a los más pobres. Pero esa pregunta supone erróneamente que nuestra riqueza es nuestra. Esta riqueza es legalmente nuestra. Pero los más pobres tienen derechos morales mucho más fuertes sobre parte de esa riqueza. Deberíamos transferir a estas personas... al menos el diez por ciento de lo que ganamos." ({{< cite Parfit2011WhatMattersVolumec "pp. 436–437" >}})

[^29]:
    Sobre el tema del sacrificio, John Stuart Mill escribió que "La moral utilitarista sí reconoce en el ser humano el poder de sacrificar su mayor bien por el bien de los demás. Sólo se niega a admitir que el sacrificio sea en sí mismo un bien. Un sacrificio que no aumenta, o tiende a aumentar, la suma total de la felicidad, lo considera un desperdicio". ({{< cite Mill2014Utilitarismo "chap. 2" >}})

[^30]:
    Sin embargo, esto no significa que el utilitarismo aspire a la igualdad perfecta en los resultados materiales o incluso en el bienestar. Joshua Greene señala que "un mundo en el que todos obtienen el mismo resultado hagan lo que hagan es un mundo ocioso en el que la gente tiene pocos incentivos para hacer algo. Así pues, la forma de maximizar la felicidad no es decretar que todo el mundo sea igual de feliz, sino animar a la gente a comportarse de forma que maximice la felicidad. Cuando medimos nuestro éxito moral, contamos la felicidad de todos por igual, pero tener éxito implica casi con toda seguridad la desigualdad tanto de la riqueza material como de la felicidad. Esa desigualdad no es ideal, pero se justifica porque, sin ella, las cosas serían peores en general.

    {{< cite Greene2013MoralTribes "p. 163" >}} Véase también [la objeción de igualdad al utilitarismo](/objeciones/igualdad/).

[^31]: En la práctica, el fenómeno psicológico de la _aversión a la pérdida_ significa que alguien puede sentirse _más molesto_ por lo que percibe como una "pérdida" que por lo que percibe como la mera "no obtención un beneficio". Estos sentimientos negativos pueden reducir aún más su bienestar, convirtiendo el juicio de que "la pérdida es peor" en una especie de profecía que acarrea su propio cumplimiento. Pero esto depende de fenómenos psicológicos contingentes que generan daños _adicionales_; no es que la pérdida sea _en sí misma_ peor.
[^32]: {{< cite Bostrom2006ReversalTestEliminating >}}
[^33]: Hay otros tipos de argumentos genealógicos que no se basan en la evolución. Consideremos que en la mayoría de las sociedades occidentales el cristianismo fue la religión dominante durante más de mil años, lo que explica por qué las intuiciones morales basadas en la moral cristiana siguen estando muy extendidas. Por ejemplo, muchos cristianos devotos tienen fuertes intuiciones morales sobre las relaciones sexuales, que los no cristianos no suelen compartir, como la intuición de que está mal mantener relaciones sexuales antes del matrimonio o que está mal que dos hombres mantengan relaciones sexuales. El discurso entre los académicos de la filosofía moral suele desestimar estas intuiciones morales condicionadas por la religión. Por tanto, muchos filósofos, incluidos la mayoría de los utilitaristas, no darían mucha importancia a las intuiciones de los cristianos sobre las relaciones sexuales.
[^34]: {{< cite "Lazari-Radek2012ObjectivityEthicsUnity" >}}
[^35]: {{< cite Greene2008SecretJokeKant >}}
