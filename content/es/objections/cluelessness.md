---
title: "La objeción de la incertidumbre radical"
slug: "incertidumbre-radical"
date: 2023-03-08
tipo: "page"
draft: false
menu: ["objections"]
weight: 8
page: 8
description: "¿Se ve socavado el utilitarismo por nuestra incapacidad para predecir las consecuencias a largo plazo de nuestras acciones? Este artículo explora si los utilitaristas pueden seguir guiándose por el valor esperado a corto plazo incluso cuando es pequeño en comparación con el valor o disvalor potencial de las consecuencias a largo plazo desconocidas."
gradientTop: "#260380"
gradientBottom: "#6F4BC9"
---

{{< TOC >}}

El utilitarismo nos ordena promover el bienestar general. Pero no podemos estar seguros de cómo hacerlo. Peor aún, hay razones de peso para pensar que _no tenemos la menor idea_ de cuáles son las consecuencias a largo plazo de nuestras acciones, ni siquiera de si serán positivas o negativas en términos generales. ¿Vuelve esto inviable al utilitarismo? ¿Es una razón para pensar que el utilitarismo es _falso_?

## La objeción epistémica al consecuencialismo

El artículo <cite>[@Lenman2000ConsequentialismCluelessness]</cite> de James Lenman presenta una influyente _objeción epistémica_ contra el [consecuencialismo](../elementos-y-tipos-de-utilitarismo.md#consecuencialismo) (y por lo tanto, por extensión, contra el utilitarismo). Podemos reconstruir el argumento aproximadamente de la siguiente manera:

> P1. No tenemos la menor idea de cuáles serán los efectos a largo plazo de cualquiera de nuestras acciones.
>
> P2. Pero los efectos a largo plazo determinan lo que deberíamos hacer, según el consecuencialismo. Por lo tanto, si el consecuencialismo es cierto, no tenemos la menor idea de lo que realmente debemos hacer: nuestras razones para actuar[^1] están fuera de nuestro alcance epistémico.
>
> P3. Pero una teoría ética adecuada debe guiar la acción: no puede postular razones más allá de nuestro alcance epistémico.
>
> Por lo tanto,
>
> C. El consecuencialismo no es una teoría ética adecuada.

Examinemos cada una de las tres premisas.

### Premisa 1: incertidumbre radical a largo plazo

Imaginemos que hace muchos siglos un médico salvó la vida a una mujer embarazada,[^2] lo que parece un acto claramente bueno. Pero resulta que la mujer era antepasada de Hitler. El acto aparentemente bueno tuvo consecuencias desastrosas.

Este ejemplo ilustra cómo podríamos no comprender los efectos a largo plazo de nuestras acciones. Pero la cuestión se generaliza incluso a acciones menos dramáticas, ya que los pequeños cambios pueden repercutir de forma impredecible en el futuro. Por ejemplo, la decisión de una persona de conducir o no un día determinado "adelantará o retrasará los viajes de muchas otras personas, aunque sólo sea unos segundos",[^3] y éstas, a su vez, afectarán ligeramente a otras personas. Finalmente, la cadena causal afectará (aunque sea ligeramente) el momento en que una pareja conciba un hijo. Un espermatozoide diferente fecundará el óvulo y nacerá un niño totalmente distinto. Esta persona distinta tomará decisiones vitales diferentes, que influirán en el momento de la concepción de otras parejas y en la identidad de los hijos que tengan, transformando el futuro en algo cada vez más diferente de lo que habría sido de otro modo. En consecuencia, debemos esperar que nuestras acciones cotidianas tengan consecuencias trascendentales, aunque impredecibles, a largo plazo. Algunos de estos efectos serán seguramente muy malos, y otros muy buenos. (Puede que provoquemos la aparición de algunos dictadores genocidas dentro de miles de años y evitemos la de otros.) Y no tenemos la menor idea de cuál será el saldo neto.

Las consecuencias a largo plazo superan a las de corto plazo en valor total. Y como en general no podemos predecir las consecuencias a largo plazo de nuestras acciones, se deduce que en general no podemos predecir las consecuencias _generales_ de nuestras acciones.

Pero puede haber algunas excepciones. Los partidarios del [largoplacismo](../utilitarismo-y-etica-practica.md#largoplacismo) creen que algunas acciones —como [reducir el riesgo existencial](../actuar-conforme-al-utilitarismo.md#reducir-el-riesgo-existencial)— tienen un valor esperado muy positivo a largo plazo. Así que, como mínimo, la subconclusión (premisa 2) debería reemplazarse por la afirmación más débil de que no tenemos la menor idea de lo que debemos hacer _aparte de intentar reducir los riesgos existenciales_. Pero incluso esta afirmación debilitada seguiría siendo sorprendente: parece que _también_ tenemos buenas razones para salvar vidas aquí y ahora. La siguiente sección evalúa si esto es así.

### Premisa 2: incertidumbre radical y valor esperado

La respuesta natural a las preocupaciones por la incertidumbre radical es pasar al [consecuencialismo de expectativas](../elementos-y-tipos-de-utilitarismo.md#utilitarismo-de-expectativas-y-utilitarismo-objetivo): promover el valor esperado en lugar del valor real. Además, en cuanto [teoría multinivel](../elementos-y-tipos-de-utilitarismo.md#utilitarismo-multinivel-y-utilitarismo-de-un-solo-nivel), el utilitarismo permite que promovamos mejor el valor esperado [recurriendo a heurísticas más que a cálculos explícitos](../utilitarismo-y-etica-practica.md#respetar-las-normas-morales-de-sentido-comun) de las probabilidades de todos y cada uno de los posibles resultados. Así que si salvar vidas a corto plazo suele tener un valor esperado positivo, eso bastaría para rechazar la objeción de la incertidumbre radical.

Lenman distingue entre las consecuencias "visibles" (epistémicamente accesibles) e "invisibles" (totalmente incognoscibles) de una acción.[^4] Utilizando esta distinción, se puede argumentar rápidamente que salvar vidas tiene un valor esperado positivo. Al fin y al cabo, si no tenemos la menor idea de cuáles serán las consecuencias a largo plazo de una acción, entonces estas consideraciones "invisibles" (dada nuestra evidencia) simplemente no dicen nada, es decir, no hablan ni a favor ni en contra de ninguna opción concreta. Por tanto, las razones visibles se imponen, sin enfrentar oposición. Por ejemplo, salvar la vida de un niño tiene un valor esperado de "una vida salvada", que no cambia cuando se señala nuestra ignorancia a largo plazo.

A Lenman esta respuesta no lo convence,[^5] pero las razones que ofrece son todas muy discutibles. Aquí nos centraremos en sus dos objeciones principales.[^6]

En primer lugar, sugiere que los consecuencialistas de expectativas deben basarse en principios de indiferencia probabilística controvertidos (la idea de que, por defecto, deberíamos asumir que todas las posibilidades son igualmente probables).

En respuesta, Hilary Greaves argumenta que algún principio de indiferencia restringido parece claramente justificado en casos simples de incertidumbre radical, independientemente de los problemas que pudieran afectar a un principio de este tipo completamente general.[^7] Después de todo, parecería totalmente injustificado tener expectativas asimétricas (en lugar de 50/50) sobre la probabilidad de que salvar hoy la vida de una persona pueda causar o evitar que se produzcan genocidios dentro de milenios. Así que podemos ignorar razonablemente esos factores causales aleatorios.

Sin embargo, como señala la propia Greaves, esto deja sin resolver los casos de "incertidumbre radical compleja", que implican no sólo algunas razones para pensar que una opción es _sistemáticamente mejor_ que otra para el futuro a largo plazo, sino también otras razones para creer lo contrario, y no está claro cómo sopesar estas distintas razones.[^8] Por ejemplo, si evitar la muerte de niños por malaria tiende a resultar en un aumento duradero de la población mundial, hay algunas razones para juzgarlo positivamente, y otras razones para juzgarlo malo globalmente (debido a la "superpoblación")[^9]. Si estamos seguros de que existe un efecto sistemático, pero no estamos seguros de su dirección, entonces es menos obvio que sea razonable ignorarlo. Al menos, no parece que el principio de indiferencia se aplique adecuadamente en este caso: no parece justificado suponer que una población mayor tenga las mismas probabilidades de ser buena o mala.

No obstante, los consecuencialistas pueden repetir el argumento anterior de que las razones "invisibles" (incognoscibles) no pueden guiar nuestras acciones, por lo que las únicas razones que nos quedan son las "visibles" (cognoscibles), que hablan a favor de salvar vidas y otros actos aparentemente buenos hasta que se demuestre lo contrario. Esta respuesta no se basa en ningún principio de indiferencia. En lugar de ello, subraya que la carga de la prueba recae en el escéptico, que debe demostrar _cómo_ deberíamos revisar nuestro juicio inicial de que salvar la vida de un niño tiene un valor esperado de "una vida salvada". Darnos por vencido ante una situación de incertidumbre radical compleja no parece preferible. Así que, hasta tanto se nos ofrezca una alternativa mejor, lo más razonable es mantener nuestro juicio inicial.[^10]

En segundo lugar, Lenman parte de la base de que, dada la inmensidad de lo "invisible" que está en juego en el largo plazo, la razón "visible" para que los consecuencialistas salven una vida debe ser extremadamente débil, apenas "una gota en el océano",[^11] pero esto es erróneo. En términos absolutos, salvar una vida es increíblemente importante. La presencia de intereses invisibles aún mayores no cambia el peso absoluto de esta razón.

Se podría suponer que, si el consecuencialismo fuera cierto, la fuerza de una razón para actuar debe ser proporcional a la probabilidad de que la acción maximice el valor global. Según este supuesto, dado que es muy poco probable que el valor de una vida incline la balanza cuando se compara el valor a largo plazo de cada opción, salvar una vida debe ser una razón "extremadamente débil" para elegir una opción en lugar de otra. Pero la suposición anterior es falsa. La fuerza de una razón consecuencialista viene dada por su valor (esperado) asociado en términos absolutos: lo que importa es el tamaño de la gota, no el tamaño del océano.

### Por qué importa el valor esperado

Dejando a un lado las objeciones específicas, la mayor preocupación de Lenman es que no está claro _por qué_ los consecuencialistas deberían preferir perspectivas con mayor valor esperado, si no tenemos la menor idea de las consecuencias reales.[^12]

Se trata de una cuestión sutil. El objetivo de guiarse por el valor esperado _no_ es aumentar nuestra probabilidad de hacer lo que sea mejor objetivamente, ya que algunas perspectivas arriesgadas que tienen pocas probabilidades de salir bien pueden, no obstante, justificar el riesgo.[^13] En términos generales, es una forma de _promover el valor de la mejor manera posible_ dada la información de que disponemos (equilibrando lo que está en juego y las probabilidades).[^14] Después de todo, si fuera posible identificar una alternativa mejor, seguirla maximizaría el valor esperado. Por tanto, si la crítica de Lenman fuera acertada, implicaría no que maximizar el valor esperado carece de fundamento, sino más bien que (en contra de las apariencias iniciales) salvar una vida carece de valor esperado positivo después de todo.

En cambio, si se pregunta: “¿Por qué pensamos que salvar una vida tiene un valor esperado positivo?", se puede responder simplemente: "¿Por qué no? Es algo visiblemente positivo, y difícilmente se puede demostrar que las consideraciones invisibles cuentan en su contra."

Hay que reconocer que estar en una situación de incertidumbre radical ante lo mucho que está en juego a largo plazo puede ser angustioso. Debería hacernos desear más información y motivarnos para realizar investigaciones largoplacistas siempre que sea posible. Pero si tales investigaciones no resultan factibles, no debemos confundir este sentimiento residual de angustia con una razón para dudar de que podamos seguir guiándonos racionalmente por las consideraciones a menor escala que sí vemos. Para poner en duda esto último, no basta con que el escéptico apele vagamente a lo profundamente desconocido. Lo desconocido, como tal, no socava nuestra base epistémica (tragándose con voracidad todo lo que sí se conoce). Para socavar un veredicto de valor esperado, hay que demostrar que algún veredicto alternativo es epistémicamente superior. Los defensores de la objeción epistémica, como los escépticos radicales en muchos otros contextos filosóficos, no han hecho tal cosa.[^15]

### Premisa 3: la posibilidad de la incertidumbre radical moral

La premisa final del argumento epistémico afirma que _una teoría ética adecuada debe guiar la acción_: no puede postular razones morales más allá de nuestro alcance epistémico. Pero, ¿por qué pensar esto? Ciertamente podemos _albergar la esperanza_ de que nos sirva de guía para la acción. Pero si el mundo no coopera —si no tenemos acceso a los hechos moralmente relevantes— entonces parece más apropiado culpar al mundo, no a una teoría moral que (¡con razón!) reconoce que los acontecimientos imprevisibles siguen siendo importantes.

El utilitarismo como teoría moral puede entenderse como una combinación de (i) [bienestarismo imparcial agregativo](../elementos-y-tipos-de-utilitarismo.md#la-definicion-de-utilitarismo) como explicación de los objetivos morales correctos (es decir, lo que importa, o lo que debería importarnos), y (ii) el principio teleológico de que nuestras razones para actuar son dadas por la aplicación de la _racionalidad instrumental_ a los _objetivos morales correctos_. Esto significa que una acción equivocada debe provenir o bien de objetivos morales equivocados o bien de perseguir objetivos morales de manera ineficaz.

Así pues, para que una objeción al utilitarismo lo amenace realmente, debe socavar una de estas dos afirmaciones. Lo más habitual es que los críticos cuestionen el relato utilitarista de lo que importa, por ejemplo sugiriendo que también deberían importarnos, por razones independientes, [los derechos](./derechos.md), [la igualdad](./igualdad.md), o [nuestros seres más queridos](./obligaciones-especiales.md). Pero la objeción de la incertidumbre radical no nos da ninguna razón para dudar de que [las personas futuras realmente importan](../utilitarismo-y-etica-practica.md#largoplacismo) y, por tanto, de que los agentes morales deben preocuparse por el bienestar de las personas futuras.[^16] Puede que simplemente sea un hecho triste del mundo que realmente no sepamos cómo alcanzar nuestros objetivos morales.

Por ejemplo, supongamos que tenemos que accionar una palanca mágica hacia la izquierda o hacia la derecha, y sólo se nos dice que el destino del mundo depende de la dirección en la que se mueva la palanca. No tenemos forma de saber qué opción salvará al mundo. Pero sería extraño concluir de ello que el destino del mundo no tiene importancia moral. Parecería más razonable concluir que estamos en una situación difícil y (a falta de más evidencia sobre qué opción tiene más probabilidades de salvar el mundo) la moral no puede ofrecernos ninguna orientación útil en estas circunstancias.

Así que la premisa 3 parece errónea.[^17] Siempre es posible que los agentes sean incapaces de saber cómo alcanzar sus objetivos morales. En tal caso, la teoría moral verdadera podría no servir de guía para la acción. Pero eso no socava su verdad. No hay ninguna razón fundamental para preferir una teoría alternativa que ofrezca una "guía" adicional que no sirva para alcanzar los objetivos morales correctos.

Todas las teorías plausibles deberían estar de acuerdo en que las consecuencias globales se encuentran _entre_ las consideraciones que importan (incluso si difieren del consecuencialismo al afirmar que además importan otros factores). Los deontólogos moderados, por ejemplo, postulan restricciones deónticas adicionales, pero permiten que sean desestimadas cuando lo que está en juego es suficientemente importante. Esto sugiere que la objeción de la incertidumbre radical debería presentarse como una objeción a todos los teóricos morales, no sólo a los consecuencialistas. Estos teóricos pueden responder de manera similar que la incertidumbre radical es (como mucho) una dificultad práctica, y no una objeción a la _verdad_ de una teoría moral.[^18]

## Conclusión

Hay razones para dudar de que la incertidumbre radical constituya realmente una _objeción_ al utilitarismo. Puede que estar en una situación de incertidumbre radical sólo sea una triste consecuencia de las circunstancias en las que nos encontramos. Pero consideraciones relativas al valor esperado, mediadas por heurísticas plausibles, pueden seguir sirviéndonos de guía. Podría ser razonable considerar que el valor esperado de una acción es su valor esperado a corto plazo, aunque no tengamos la menor idea de sus consecuencias a largo plazo. Asimismo, incluso si la incertidumbre radical a largo plazo eclipsa el valor esperado a corto plazo, puede que siga habiendo algunas opciones —como trabajar para reducir el riesgo existencial— que tengan un valor esperado a largo plazo claramente positivo. Así que, después de todo, el utilitarismo no tiene por qué dejarnos completamente en una situación de incertidumbre radical sobre [cómo actuar](../actuar-conforme-al-utilitarismo.md).

{{< next-page-objection >}}

{{< how-to-cite authors="Chappell, R.Y." >}}

{{< button >}}

## Recursos y Más información

- [@Burch-Brown2014CluesConsequentialists].
- [@Greaves2016Cluelessness].
- [@Lenman2000ConsequentialismCluelessness].
- [@Mogensen2020MaximalCluelessness].
- [@Mogensen2021ParalysisArgument].
- [@Thorstad2020HeuristicsCluelessAgents].

[^1]:
     Es decir, las consideraciones que cuentan a favor de actuar de una manera y no de otra.

[^2]:
     Adaptado de [@Lenman2000ConsequentialismCluelessness, p. 344].

[^3]:
     [@Greaves2016Cluelessness, p. 314].

[^4]:
     [@Lenman2000ConsequentialismCluelessness, p. 363].

[^5]:
     Véase [@Lenman2000ConsequentialismCluelessness, pp. 353-359].

[^6]:
     Lenman ofrece cuatro objeciones en total. La cuarta presupone la segunda, por lo que se aborda en nuestra respuesta a esa objeción. La tercera objeta que necesitamos distinguir dos razones muy diferentes para juzgar que un acto carece de valor esperado: (i) podríamos _saber_ que no hay diferencia, o (ii) podríamos _no tener la menor idea_ de si es increíblemente bueno o increíblemente malo. Dado que estos dos estados epistémicos son tan diferentes, razona Lenman, no tiene sentido tratarlos de la misma manera.

    Es cierto que se trata de una diferencia significativa. Pero es un error asumir que cualquier cosa moralmente significativa debe cambiar la forma en que evaluamos los _actos_, cuando a menudo las _actitudes_ son más adecuadas para reflejar dicha importancia. Sentiríamos mucha más angustia y ambivalencia —y desearíamos que hubiera más información disponible— en un caso de "incertidumbre total" de alto riesgo que en un caso de "cero conocido". Esto parece suficiente para reflejar la diferencia.

[^7]:
     [@Greaves2016Cluelessness, sec. IV].

[^8]:
     [@Greaves2016Cluelessness, sec. V]. Véase también [@Mogensen2020MaximalCluelessness].

[^9]:
     Para una exploración sobre si el mundo está superpoblado o infrapoblado, véase [@Ord2014OverpopulationUnderpopulation].

[^10]:
Para una defensa relacionada de la "racionalidad procedimental" de confiar en las heurísticas ante una situación de incertidumbre radical, véase [@Thorstad2020HeuristicsCluelessAgents].

     Que valga la pena evaluar las inquietudes relativas a la superpoblación más a fondo dependerá de factores como (i) cuántos recursos están en juego (es plausible que una organización que dona miles de millones de dólares tenga más razones para investigar que un particular que dona cientos de dólares) y (ii) lo tratable que parezca la incertidumbre, o cuál es el valor de la información que se espera de una investigación más exhaustiva. Para un pequeño donante con pocas posibilidades de resolver rápidamente su incertidumbre, a menudo lo más razonable será ignorar por completo la incertidumbre radical.

[^11]:
     [@Lenman2000ConsequentialismCluelessness, p. 356].

[^12]:
     [@Lenman2000ConsequentialismCluelessness, p. 360].

[^13]:
     Por ejemplo, un 10% de probabilidades de salvar un millón de vidas es mejor en términos esperados que salvar una vida con seguridad, aunque esta última opción tenga un 90% de probabilidades de producir un resultado mejor. Lo que importa son las magnitudes y probabilidades exactas, y no lo que es "más probable" que sea mejor (por poco que sea).

[^14]:
     Una característica importante de la maximización del valor esperado es que no podemos esperar que ninguna alternativa que podamos identificar subjetivamente tenga mejores resultados en el límite (es decir, imaginando que decisiones similares se repiten un número suficiente de veces, en diferentes mundos posibles de ser necesario).

[^15]:
     Una propuesta interesante es que deberíamos tener _grados de creencia imprecisos_ que cubran una amplia gama de dogmas que parezcan razonables. Una de las preocupaciones de este tipo de propuestas es que podrían implicar que tenemos tantas razones para apoyar a la _Fundación por la Malaria_ como a la _Fundación contra la Malaria_, lo que puede socavar la aparente razonabilidad de los supuestos de los que se parte. Cf. [@Mogensen2020MaximalCluelessness].

[^16]:
Resulta sorprendente que incluso Lenman ([@Lenman2000ConsequentialismCluelessness, p. 364]) admita que “es muy plausible que las consecuencias invisibles de la acción también importen”, aunque añada que “no hay ninguna razón clara para suponer que esta importancia sea moralmente relevante, así como tampoco son cuestiones de preocupación moral las consecuencias, visibles o no, de los terremotos o de los impactos de meteoritos (aunque ciertamente pueden importar enormemente). No hay nada particularmente irrazonable en ello. Se trata simplemente de decir, por ejemplo, que los crímenes de Hitler, aunque fueron algo terrible, no son algo que podamos plantear sensatamente en la discusión sobre las deficiencias o excelencias morales de [alguien que salvó la vida de un antepasado lejano de Hitler]".

    Este es un uso extraño de "importancia moral". Está claro que los agentes morales deberían preocuparse por los terremotos, los meteoritos y los futuros dictadores genocidas. (Como mínimo, deberíamos preferir que hubiera menos de esas cosas, como parte de nuestra preocupación benéfica por los demás en general.) Un agente que fuera realmente _indiferente_ a estas cosas no sería un agente virtuoso: su indiferencia revela un desprecio insensible por las personas futuras. Por tanto, no cabe duda de que podría constituir un "fallo moral" no preocuparse por tales acontecimientos perniciosos.

    Por otro lado, si Lenman realmente sólo quiere decir que _el hecho de que ocurran realmente determinadas consecuencias imprevisibles_ no debería alterar nuestra valoración de las "deficiencias o excelencias morales" de una persona, entonces esto parece una verdad de Perogrullo que no amenaza en modo alguno el consecuencialismo. Es un punto conocido que muchas formas de evaluación agencial (por ejemplo, la racionalidad, la virtud, etc.) son “internalistas” —en el sentido de que sobrevienen a las propiedades intrínsecas del agente, y no a lo que sucede en el mundo externo, más allá de su control. [Los utilitaristas híbridos](/tipos-de-utilitarismo#utilitarismo-global-y-utilitarismo-híbrido) combinan cómodamente ese internalismo sobre las valoraciones agenciales con un análisis utilitarista de nuestras razones para actuar.

[^17]:
A menos que se interprete en el sentido de que ya no se exija orientación donde no es posible. Si bien es cierto que está bien tener razones relativas a los hechos que exceden nuestro alcance epistémico, una versión más convincente de la premisa podría simplemente afirmar que las razones relativas a la evidencia deben estar dentro de nuestro alcance epistémico. Pero entonces se corre el riesgo de caer en una mera tautología: por definición, las "razones relativas a la evidencia" postuladas por cualquier teoría —incluido el consecuencialismo— serán epistémicamente accesibles (suponiendo que "evidencia" y "acceso epistémico" vayan juntos). La cuestión, en cambio, es qué razones relativas a la evidencia (si las hay) implica la teoría que tenemos.

[^18]: Aunque hay algunas razones para pensar que las dificultades prácticas pueden ser aún peores para los no consecuencialistas. Véase [@Mogensen2021ParalysisArgument].
